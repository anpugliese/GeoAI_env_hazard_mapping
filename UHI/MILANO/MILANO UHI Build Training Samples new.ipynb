{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bb5bf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "#Defining libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4541635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1-11-> Residential urban areas \n",
    "2-121,13->Industrial and abbandoned urban areas\n",
    "3-122,123,124 Transportation infrastructure (streets, highways, airports, and ports)\n",
    "4-14->Urban green areas\n",
    "5-2->Agricultural areas\n",
    "6-3->Forest\n",
    "7-4/5->Hydro and humid bodies\n",
    "'''\n",
    "#Convert from copernicus code 2018 to an internal code\n",
    "URBAN = 1\n",
    "INDUSTRIAL = 2\n",
    "TRANSPORTATION = 3\n",
    "URBAN_VEGETATION = 4\n",
    "RURAL = 5\n",
    "FOREST = 6\n",
    "WATER = 7\n",
    "LC_NO_DATA = 9999\n",
    "NO_DATA= -9999\n",
    "    \n",
    "# Function to check if the file is a tiff and must be read.\n",
    "def check_wrong_files(f):\n",
    "    if f == 'clip': return True #avoid entering the \"clip\" folder\n",
    "    if 'csv'in f: return True\n",
    "    if f in ['LC08_L2SP_194028_20170524_20200903_02_T1']: return True #Not consider the 2017 image as it biases the model\n",
    "    if 'ipynb' in f: return True #avoid entering the \"ipynb_checkpoint\" file\n",
    "    if 'tar' in f: return True #avoid entering \"tar\" files\n",
    "    if 'aux' in f: return True #avoid entering \"aux\" files\n",
    "    return False\n",
    "\n",
    "def match_landsat_to_landcover(landsat):\n",
    "    year = int(landsat[17:21])\n",
    "    if year in [2015,2016]:\n",
    "        return str(2015)\n",
    "    elif year in [2017,2018,2019]:\n",
    "        return str(2018)\n",
    "    elif year in [2020,2021,2022]:\n",
    "        return str(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2b6c41d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# City parameters and global variables\n",
    "city_info = {\n",
    "    \"resolution\": 5,\n",
    "    \"epsg\": 32632,\n",
    "    \"capitalized\": \"Milan\"\n",
    "}\n",
    "\n",
    "city = 'MILANO'\n",
    "current_city_info = city_info\n",
    "city_epsg = current_city_info['epsg']\n",
    "data_folder = \"data\"\n",
    "#landcover_path = f'{landcover_base_path}/DUSAF_MCM_mapped_{year}.tif'\n",
    "\n",
    "landsat_raster_folder = \"/home/user/ODC_harmonia/Landsat/Milan/data\"\n",
    "sat_images_path = f\"{landsat_raster_folder}/clip\"\n",
    "file_list = os.listdir(f\"{sat_images_path}\")\n",
    "landcover_base_path = f'{data_folder}/landcover'\n",
    "#landsat_raster_file_list = os.listdir(f\"{landsat_raster_folder}\")\n",
    "\n",
    "total_samples_per_raster = 50000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bec494b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lst = None\n",
    "predict_ndvi = None\n",
    "predict_ndbi = None\n",
    "predict_albedo = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e62a5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23814686",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing LC08_L2SP_194028_20180815_20200831_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20190717_20200827_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20190818_20200827_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20150722_20200908_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20180730_20200831_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20220725_20220802_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20220709_20220721_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20210706_20210713_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20200820_20200905_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20220810_20220818_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20160622_20200906_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20150807_20200909_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20210722_20210729_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20150706_20200909_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20160825_20200906_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20200719_20200911_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n"
     ]
    }
   ],
   "source": [
    "#Commented out for legacy\n",
    "'''\n",
    "samples = pd.DataFrame()\n",
    "predict_n = 0\n",
    "predict_lst = None\n",
    "predict_ndvi = None\n",
    "predict_ndbi = None\n",
    "predict_albedo = None\n",
    "\n",
    "sample_n = [\n",
    "    int(total_samples_per_raster / 4), # urban, uhi 1\n",
    "    int(total_samples_per_raster / 4), # urban, uhi 0\n",
    "    int(total_samples_per_raster / 4), # rural/vegetation/bareland, uhi 1\n",
    "    int(total_samples_per_raster / 4), # rural/vegetation/bareland, uhi 0\n",
    "]\n",
    "\n",
    "for f in file_list:\n",
    "    if check_wrong_files(f): continue\n",
    "\n",
    "    print(f'Processing {f}')\n",
    "    file_date_string = f.split('_')[3] #example: LC08_L2SP_194028_20160825_20200906_02_T1_LST\n",
    "    year = match_landsat_to_landcover(f)\n",
    "    landcover_path = f'{landcover_base_path}/DUSAF_{year}_MCM_mapped.tif'\n",
    "    \n",
    "    with rasterio.open(landcover_path, driver=\"GTiff\") as landcover_raster:\n",
    "        landcover_array = landcover_raster.read(1)\n",
    "        #print(landcover_raster.profile)\n",
    "        print('Read land cover')\n",
    "        rows, cols = landcover_array.shape\n",
    "        x_positions = np.arange(0, cols)\n",
    "        y_positions = np.arange(0, rows)\n",
    "        x, y = np.meshgrid(x_positions, y_positions)\n",
    "        x_flat = x.flatten()\n",
    "        y_flat = y.flatten()\n",
    "        values_flat = landcover_array.flatten()\n",
    "\n",
    "        # Create a DataFrame for the Landcover \n",
    "        landcover_df = pd.DataFrame({'x': x_flat, 'y': y_flat, 'landcover': values_flat})\n",
    "        landcover_df['landcover'] = landcover_df['landcover']\n",
    "    if not isinstance(predict_lst,np.ndarray) and not isinstance(predict_ndvi,np.ndarray) and not isinstance(predict_ndbi,np.ndarray) and not isinstance(predict_albedo,np.ndarray):\n",
    "        predict_lst = np.zeros_like(landcover_array)\n",
    "        predict_ndvi = np.zeros_like(landcover_array)\n",
    "        predict_ndbi = np.zeros_like(landcover_array)\n",
    "        predict_albedo = np.zeros_like(landcover_array)\n",
    "\n",
    "    #columns in the end: x,y,landcover,ndvi,raster\n",
    "    train_df = landcover_df.copy()\n",
    "\n",
    "    #add the uhi column\n",
    "    with rasterio.open(f\"{sat_images_path}/{f}/{f}_uhi.tif\", driver=\"GTiff\") as uhi_raster:\n",
    "        print('read UHI')\n",
    "        uhi_array = uhi_raster.read(1) #UHI band\n",
    "        uhi_flat = uhi_array.flatten()\n",
    "        train_df['uhi'] = pd.Series(uhi_flat).astype('int16')\n",
    "\n",
    "    #add the uhi intensity column\n",
    "    #Uncomment to switch to UHI Intensity instead of UHI binary\n",
    "    \n",
    "    with rasterio.open(f\"{sat_images_path}/{f}/{f}_uhi_int.tif\", driver=\"GTiff\") as uhii_raster:\n",
    "        print('read UHII')\n",
    "        uhii_array = uhii_raster.read(1) #UHI band\n",
    "        uhii_flat = uhii_array.flatten()\n",
    "        train_df['uhii'] = pd.Series(uhii_flat).astype('float32')\n",
    "    \n",
    "    #add the ndvi column\n",
    "    with rasterio.open(f\"{sat_images_path}/{f}/{f}_NDVI.TIF\", driver=\"GTiff\") as ndvi_raster:\n",
    "        print('read NDVI')\n",
    "        ndvi_array = ndvi_raster.read(1) #UHI band\n",
    "        ndvi_flat = ndvi_array.flatten()\n",
    "        train_df['ndvi'] = pd.Series(ndvi_flat).astype('float32')\n",
    "    \n",
    "    #add the ndbi column\n",
    "    with rasterio.open(f\"{sat_images_path}/{f}/{f}_NDBI.TIF\", driver=\"GTiff\") as ndbi_raster:\n",
    "        print('read NDBI')\n",
    "        ndbi_array = ndbi_raster.read(1) #UHI band\n",
    "        ndbi_flat = ndbi_array.flatten()\n",
    "        train_df['ndbi'] = pd.Series(ndbi_flat).astype('float32')\n",
    "    \n",
    "    #add the albedo column\n",
    "    with rasterio.open(f\"{sat_images_path}/{f}/{f}_albedo.TIF\", driver=\"GTiff\") as albedo_raster:\n",
    "        print('read albedo')\n",
    "        albedo_array = albedo_raster.read(1) #UHI band\n",
    "        albedo_flat = albedo_array.flatten()\n",
    "        train_df['albedo'] = pd.Series(albedo_flat).astype('float32')\n",
    "\n",
    "    #add the LST column\n",
    "    with rasterio.open(f\"{sat_images_path}/{f}/{f}_LST.TIF\", driver=\"GTiff\") as lst_raster:\n",
    "        print('read LST')\n",
    "        lst_array = lst_raster.read(1) #UHI band\n",
    "        lst_flat = lst_array.flatten()\n",
    "        train_df['lst'] = pd.Series(lst_flat).astype('float32')\n",
    "\n",
    "    if int(year) >= 2020:\n",
    "        predict_n += 1\n",
    "        predict_lst = np.where(landcover_array != LC_NO_DATA, (predict_lst + lst_array), -9999)\n",
    "        predict_ndvi = np.where(landcover_array != LC_NO_DATA, (predict_ndvi + ndvi_array), -9999)\n",
    "        predict_ndbi = np.where(landcover_array != LC_NO_DATA, (predict_ndbi + ndbi_array), -9999)\n",
    "        predict_albedo = np.where(landcover_array != LC_NO_DATA, (predict_albedo + albedo_array), -9999)\n",
    "\n",
    "\n",
    "    train_df['raster'] = int(file_date_string)\n",
    "\n",
    "    #remove nodata (-9999) from the dataframe\n",
    "    train_df = train_df.loc[\n",
    "        (train_df['landcover'] != LC_NO_DATA)\n",
    "    ]\n",
    "   #urban, uhi = 0\n",
    "    condition = (\n",
    "        ((train_df['landcover'] == URBAN) | \n",
    "         (train_df['landcover'] == INDUSTRIAL) | \n",
    "         (train_df['landcover'] == TRANSPORTATION)) & \n",
    "        (train_df['uhi'] == 0)\n",
    "    )\n",
    "    sampling = train_df.loc[\n",
    "        condition\n",
    "    ].sample(n=sample_n[0])\n",
    "    samples = pd.concat([samples, sampling])\n",
    "\n",
    "    #urban, uhi = 1\n",
    "    condition = (\n",
    "        ((train_df['landcover'] == URBAN) | \n",
    "         (train_df['landcover'] == INDUSTRIAL) | \n",
    "         (train_df['landcover'] == TRANSPORTATION)) & \n",
    "        (train_df['uhi'] == 1)\n",
    "    )\n",
    "    sampling = train_df.loc[\n",
    "        condition\n",
    "    ].sample(n=sample_n[1])\n",
    "    samples = pd.concat([samples, sampling])\n",
    "\n",
    "    #rural/forest/bareland, uhi = 0\n",
    "    condition = (\n",
    "        ((train_df['landcover'] == URBAN_VEGETATION) | \n",
    "         (train_df['landcover'] == RURAL) | \n",
    "         (train_df['landcover'] == FOREST)) & \n",
    "         (train_df['uhi'] == 0)\n",
    "    ) \n",
    "    sampling = train_df.loc[\n",
    "        condition\n",
    "    ].sample(n=sample_n[2])\n",
    "    samples = pd.concat([samples, sampling])\n",
    "\n",
    "    #rural/forest/bareland, uhi = 1\n",
    "    condition = (\n",
    "        ((train_df['landcover'] == URBAN_VEGETATION) | \n",
    "         (train_df['landcover'] == RURAL) | \n",
    "         (train_df['landcover'] == FOREST))& \n",
    "         (train_df['uhi'] == 1)\n",
    "    ) \n",
    "    sampling = train_df.loc[\n",
    "        condition\n",
    "    ].sample(n=sample_n[3])\n",
    "    samples = pd.concat([samples, sampling])\n",
    "    \n",
    "    \n",
    "    all_samples.append(samples)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3296b6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing LC08_L2SP_194028_20180815_20200831_02_T1\n",
      "data/landcover/DUSAF_2018_MCM_mapped.tif\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "Processing LC08_L2SP_194028_20190717_20200827_02_T1\n",
      "data/landcover/DUSAF_2018_MCM_mapped.tif\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "Processing LC08_L2SP_194028_20190818_20200827_02_T1\n",
      "data/landcover/DUSAF_2018_MCM_mapped.tif\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "Processing LC08_L2SP_194028_20150722_20200908_02_T1\n",
      "data/landcover/DUSAF_2015_MCM_mapped.tif\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "Processing LC08_L2SP_194028_20180730_20200831_02_T1\n",
      "data/landcover/DUSAF_2018_MCM_mapped.tif\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "Processing LC08_L2SP_194028_20220725_20220802_02_T1\n",
      "data/landcover/DUSAF_2021_MCM_mapped.tif\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "Processing LC08_L2SP_194028_20220709_20220721_02_T1\n",
      "data/landcover/DUSAF_2021_MCM_mapped.tif\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "Processing LC08_L2SP_194028_20210706_20210713_02_T1\n",
      "data/landcover/DUSAF_2021_MCM_mapped.tif\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "Processing LC08_L2SP_194028_20200820_20200905_02_T1\n",
      "data/landcover/DUSAF_2021_MCM_mapped.tif\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "Processing LC08_L2SP_194028_20220810_20220818_02_T1\n",
      "data/landcover/DUSAF_2021_MCM_mapped.tif\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "Processing LC08_L2SP_194028_20160622_20200906_02_T1\n",
      "data/landcover/DUSAF_2015_MCM_mapped.tif\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "Processing LC08_L2SP_194028_20150807_20200909_02_T1\n",
      "data/landcover/DUSAF_2015_MCM_mapped.tif\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "Processing LC08_L2SP_194028_20210722_20210729_02_T1\n",
      "data/landcover/DUSAF_2021_MCM_mapped.tif\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "Processing LC08_L2SP_194028_20150706_20200909_02_T1\n",
      "data/landcover/DUSAF_2015_MCM_mapped.tif\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "Processing LC08_L2SP_194028_20160825_20200906_02_T1\n",
      "data/landcover/DUSAF_2015_MCM_mapped.tif\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "Processing LC08_L2SP_194028_20200719_20200911_02_T1\n",
      "data/landcover/DUSAF_2021_MCM_mapped.tif\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n"
     ]
    }
   ],
   "source": [
    "samples = pd.DataFrame()\n",
    "predict_n= None\n",
    "sample_n = [\n",
    "    int(total_samples_per_raster / 4),  # urban, uhi 1\n",
    "    int(total_samples_per_raster / 4),  # urban, uhi 0\n",
    "    int(total_samples_per_raster / 4),  # rural/vegetation/bareland, uhi 1\n",
    "    int(total_samples_per_raster / 4),  # rural/vegetation/bareland, uhi 0\n",
    "]\n",
    "\n",
    "for f in file_list:\n",
    "    if check_wrong_files(f):\n",
    "        continue\n",
    "\n",
    "    print(f'Processing {f}')\n",
    "    file_date_string = f.split('_')[3]  # Extract date from filename\n",
    "    year = match_landsat_to_landcover(f)\n",
    "    landcover_path = f'{landcover_base_path}/DUSAF_{year}_MCM_mapped.tif'\n",
    "    print(landcover_path)\n",
    "    \n",
    "    with rasterio.open(landcover_path, driver=\"GTiff\") as landcover_raster:\n",
    "        landcover_array = landcover_raster.read(1)\n",
    "        print('Read land cover')\n",
    "\n",
    "    # Initialize prediction arrays on first iteration\n",
    "    if not isinstance(predict_n,np.ndarray):\n",
    "        predict_n = np.zeros_like(landcover_array, dtype=int)\n",
    "        predict_lst = np.zeros_like(landcover_array, dtype=float)\n",
    "        predict_ndvi = np.zeros_like(landcover_array, dtype=float)\n",
    "        predict_ndbi = np.zeros_like(landcover_array, dtype=float)\n",
    "        predict_albedo = np.zeros_like(landcover_array, dtype=float)\n",
    "\n",
    "    # Load Landsat-derived rasters\n",
    "    #add the uhi column\n",
    "    with rasterio.open(f\"{sat_images_path}/{f}/{f}_uhi.tif\", driver=\"GTiff\") as uhi_raster:\n",
    "        print('read UHI')\n",
    "        uhi_array = uhi_raster.read(1) #UHI band\n",
    "\n",
    "    #add the uhi intensity column\n",
    "    #Uncomment to switch to UHI Intensity instead of UHI binary\n",
    "    \n",
    "    with rasterio.open(f\"{sat_images_path}/{f}/{f}_uhi_int.tif\", driver=\"GTiff\") as uhii_raster:\n",
    "        print('read UHII')\n",
    "        uhii_array = uhii_raster.read(1) #UHI band\n",
    "        \n",
    "    with rasterio.open(f\"{sat_images_path}/{f}/{f}_NDVI.TIF\", driver=\"GTiff\") as ndvi_raster:\n",
    "        ndvi_array = ndvi_raster.read(1)\n",
    "\n",
    "    with rasterio.open(f\"{sat_images_path}/{f}/{f}_NDBI.TIF\", driver=\"GTiff\") as ndbi_raster:\n",
    "        ndbi_array = ndbi_raster.read(1)\n",
    "\n",
    "    with rasterio.open(f\"{sat_images_path}/{f}/{f}_albedo.TIF\", driver=\"GTiff\") as albedo_raster:\n",
    "        albedo_array = albedo_raster.read(1)\n",
    "\n",
    "    with rasterio.open(f\"{sat_images_path}/{f}/{f}_LST.TIF\", driver=\"GTiff\") as lst_raster:\n",
    "        lst_array = lst_raster.read(1)\n",
    "\n",
    "    # Exclude invalid pixels from predictions\n",
    "    valid_pixels = (ndvi_array != NO_DATA) & (ndbi_array != NO_DATA) & (albedo_array != NO_DATA) & (lst_array != NO_DATA)\n",
    "\n",
    "    if int(year) >= 2020:\n",
    "        predict_n += valid_pixels  # Track valid pixel count\n",
    "        predict_lst[valid_pixels] += lst_array[valid_pixels]\n",
    "        predict_ndvi[valid_pixels] += ndvi_array[valid_pixels]\n",
    "        predict_ndbi[valid_pixels] += ndbi_array[valid_pixels]\n",
    "        predict_albedo[valid_pixels] += albedo_array[valid_pixels]\n",
    "\n",
    "    # Remove nodata pixels before sampling\n",
    "    train_df = pd.DataFrame({\n",
    "        'x': np.tile(np.arange(landcover_array.shape[1]), landcover_array.shape[0]),\n",
    "        'y': np.repeat(np.arange(landcover_array.shape[0]), landcover_array.shape[1]),\n",
    "        'landcover': landcover_array.flatten(),\n",
    "        'uhi': uhi_array.flatten(),\n",
    "        'uhii': uhii_array.flatten(),\n",
    "        'ndvi': ndvi_array.flatten(),\n",
    "        'ndbi': ndbi_array.flatten(),\n",
    "        'albedo': albedo_array.flatten(),\n",
    "        'lst': lst_array.flatten(),\n",
    "        'raster': file_date_string\n",
    "    })\n",
    "\n",
    "    train_df = train_df[\n",
    "        (train_df['landcover'] != LC_NO_DATA) & \n",
    "        (train_df['uhi'] != NO_DATA) & \n",
    "        (train_df['uhii'] != NO_DATA) & \n",
    "        (train_df['ndvi'] != NO_DATA) & \n",
    "        (train_df['ndbi'] != NO_DATA) & \n",
    "        (train_df['albedo'] != NO_DATA) & \n",
    "        (train_df['lst'] != NO_DATA)\n",
    "    ]\n",
    "\n",
    "    # Sample the valid data\n",
    "    for idx, (condition, n_samples) in enumerate([\n",
    "        (((train_df['landcover'] == URBAN) | (train_df['landcover'] == INDUSTRIAL) | (train_df['landcover'] == TRANSPORTATION)) & (train_df['uhi'] == 0), sample_n[0]),\n",
    "        (((train_df['landcover'] == URBAN) | (train_df['landcover'] == INDUSTRIAL) | (train_df['landcover'] == TRANSPORTATION)) & (train_df['uhi'] == 1), sample_n[1]),\n",
    "        (((train_df['landcover'] == URBAN_VEGETATION) | (train_df['landcover'] == RURAL) | (train_df['landcover'] == FOREST)) & (train_df['uhi'] == 0), sample_n[2]),\n",
    "        (((train_df['landcover'] == URBAN_VEGETATION) | (train_df['landcover'] == RURAL) | (train_df['landcover'] == FOREST)) & (train_df['uhi'] == 1), sample_n[3])\n",
    "    ]):\n",
    "        sampled_data = train_df.loc[condition].sample(n=n_samples, random_state=42)\n",
    "        samples = pd.concat([samples, sampled_data])\n",
    "    all_samples.append(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa22f48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving samples in training_samples/MILANO_samples_feb16_50mil.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>landcover</th>\n",
       "      <th>uhi</th>\n",
       "      <th>uhii</th>\n",
       "      <th>ndvi</th>\n",
       "      <th>ndbi</th>\n",
       "      <th>albedo</th>\n",
       "      <th>lst</th>\n",
       "      <th>raster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3050</td>\n",
       "      <td>4382</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.363373</td>\n",
       "      <td>0.736672</td>\n",
       "      <td>-0.248194</td>\n",
       "      <td>0.159342</td>\n",
       "      <td>306.016998</td>\n",
       "      <td>20180815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2246</td>\n",
       "      <td>4678</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.599213</td>\n",
       "      <td>0.620605</td>\n",
       "      <td>-0.084578</td>\n",
       "      <td>0.154965</td>\n",
       "      <td>305.781158</td>\n",
       "      <td>20180815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5775</td>\n",
       "      <td>5265</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.835052</td>\n",
       "      <td>0.745050</td>\n",
       "      <td>-0.250899</td>\n",
       "      <td>0.168430</td>\n",
       "      <td>305.545319</td>\n",
       "      <td>20180815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1434</td>\n",
       "      <td>1187</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.021576</td>\n",
       "      <td>0.621916</td>\n",
       "      <td>-0.198456</td>\n",
       "      <td>0.122757</td>\n",
       "      <td>306.358795</td>\n",
       "      <td>20180815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10715</td>\n",
       "      <td>2924</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.749603</td>\n",
       "      <td>0.873230</td>\n",
       "      <td>-0.432261</td>\n",
       "      <td>0.191063</td>\n",
       "      <td>305.630768</td>\n",
       "      <td>20180815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799995</th>\n",
       "      <td>5761</td>\n",
       "      <td>4677</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3.745911</td>\n",
       "      <td>0.638478</td>\n",
       "      <td>-0.300186</td>\n",
       "      <td>0.127515</td>\n",
       "      <td>309.161591</td>\n",
       "      <td>20200719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799996</th>\n",
       "      <td>6826</td>\n",
       "      <td>5788</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6.347015</td>\n",
       "      <td>0.367928</td>\n",
       "      <td>0.096560</td>\n",
       "      <td>0.173279</td>\n",
       "      <td>311.762695</td>\n",
       "      <td>20200719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799997</th>\n",
       "      <td>7201</td>\n",
       "      <td>2104</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8.056030</td>\n",
       "      <td>0.630161</td>\n",
       "      <td>-0.089053</td>\n",
       "      <td>0.164044</td>\n",
       "      <td>313.471710</td>\n",
       "      <td>20200719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799998</th>\n",
       "      <td>7122</td>\n",
       "      <td>4925</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3.417786</td>\n",
       "      <td>0.598087</td>\n",
       "      <td>-0.122851</td>\n",
       "      <td>0.187482</td>\n",
       "      <td>308.833466</td>\n",
       "      <td>20200719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799999</th>\n",
       "      <td>8516</td>\n",
       "      <td>2076</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4.063782</td>\n",
       "      <td>0.694874</td>\n",
       "      <td>-0.209216</td>\n",
       "      <td>0.134239</td>\n",
       "      <td>309.479462</td>\n",
       "      <td>20200719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x     y  landcover  uhi      uhii      ndvi      ndbi    albedo  \\\n",
       "0        3050  4382          1    0 -0.363373  0.736672 -0.248194  0.159342   \n",
       "1        2246  4678          1    0 -0.599213  0.620605 -0.084578  0.154965   \n",
       "2        5775  5265          1    0 -0.835052  0.745050 -0.250899  0.168430   \n",
       "3        1434  1187          2    0 -0.021576  0.621916 -0.198456  0.122757   \n",
       "4       10715  2924          2    0 -0.749603  0.873230 -0.432261  0.191063   \n",
       "...       ...   ...        ...  ...       ...       ...       ...       ...   \n",
       "799995   5761  4677          5    1  3.745911  0.638478 -0.300186  0.127515   \n",
       "799996   6826  5788          5    1  6.347015  0.367928  0.096560  0.173279   \n",
       "799997   7201  2104          4    1  8.056030  0.630161 -0.089053  0.164044   \n",
       "799998   7122  4925          5    1  3.417786  0.598087 -0.122851  0.187482   \n",
       "799999   8516  2076          4    1  4.063782  0.694874 -0.209216  0.134239   \n",
       "\n",
       "               lst    raster  \n",
       "0       306.016998  20180815  \n",
       "1       305.781158  20180815  \n",
       "2       305.545319  20180815  \n",
       "3       306.358795  20180815  \n",
       "4       305.630768  20180815  \n",
       "...            ...       ...  \n",
       "799995  309.161591  20200719  \n",
       "799996  311.762695  20200719  \n",
       "799997  313.471710  20200719  \n",
       "799998  308.833466  20200719  \n",
       "799999  309.479462  20200719  \n",
       "\n",
       "[800000 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_base_path = f'training_samples'    \n",
    "# create the \"training_samples\" folder if it does not exist\n",
    "os.makedirs(f\"{samples_base_path}\", exist_ok=True)\n",
    "sufix = '_feb16_50mil'\n",
    "\n",
    "samples_path = f'{samples_base_path}/{city}_samples{sufix}.csv'\n",
    "print(f'Saving samples in {samples_path}')\n",
    "\n",
    "samples_to_save = all_samples[len(all_samples) - 1].copy()\n",
    "samples_to_save = samples_to_save.reset_index(drop=True)\n",
    "samples_to_save.to_csv(samples_path)\n",
    "samples_to_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6712421b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 6, 6, 6],\n",
       "       [1, 1, 1, ..., 6, 6, 6],\n",
       "       [1, 1, 1, ..., 6, 6, 6]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63ca10ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute final prediction values, avoiding division by zero\n",
    "valid_mask = predict_n > 0\n",
    "predict_lst[valid_mask] /= predict_n[valid_mask]\n",
    "predict_ndvi[valid_mask] /= predict_n[valid_mask]\n",
    "predict_ndbi[valid_mask] /= predict_n[valid_mask]\n",
    "predict_albedo[valid_mask] /= predict_n[valid_mask]\n",
    "\n",
    "# Convert to DataFrame\n",
    "predict_df = pd.DataFrame({\n",
    "    'x': np.tile(np.arange(landcover_array.shape[1]), landcover_array.shape[0]),\n",
    "    'y': np.repeat(np.arange(landcover_array.shape[0]), landcover_array.shape[1]),\n",
    "    'landcover': landcover_array.flatten().astype('int32'),\n",
    "    'lst': predict_lst.flatten().astype('float32'),\n",
    "    'ndvi': predict_ndvi.flatten().astype('float32'),\n",
    "    'ndbi': predict_ndbi.flatten().astype('float32'),\n",
    "    'albedo': predict_albedo.flatten().astype('float32')\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c082eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the lst and ndvi predict\n",
    "if predict_n == 0: predict_n = 0.0000001\n",
    "predict_lst = np.where(landcover_array != LC_NO_DATA, (predict_lst / predict_n), -9999)\n",
    "predict_ndvi = np.where(landcover_array != LC_NO_DATA, (predict_ndvi / predict_n), -9999)\n",
    "predict_ndbi = np.where(landcover_array != LC_NO_DATA, (predict_ndbi / predict_n), -9999)\n",
    "predict_albedo = np.where(landcover_array != LC_NO_DATA, (predict_albedo / predict_n), -9999)\n",
    "\n",
    "predict_df = pd.DataFrame({'x': x_flat, 'y': y_flat})\n",
    "predict_df['landcover'] = pd.Series(landcover_array.flatten()).astype('int32')\n",
    "predict_df['x'] = predict_df['x'].astype('uint32')\n",
    "predict_df['y'] = predict_df['y'].astype('uint32')\n",
    "predict_df['lst'] = pd.Series(predict_lst.flatten()).astype('float32')\n",
    "predict_df['ndvi'] = pd.Series(predict_ndvi.flatten()).astype('float32')\n",
    "predict_df['ndbi'] = pd.Series(predict_ndbi.flatten()).astype('float32')\n",
    "predict_df['albedo'] = pd.Series(predict_albedo.flatten()).astype('float32')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2463e272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>landcover</th>\n",
       "      <th>lst</th>\n",
       "      <th>ndvi</th>\n",
       "      <th>ndbi</th>\n",
       "      <th>albedo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82854</th>\n",
       "      <td>3642</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>309.330048</td>\n",
       "      <td>0.848724</td>\n",
       "      <td>-0.435613</td>\n",
       "      <td>0.156589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82855</th>\n",
       "      <td>3643</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>309.330048</td>\n",
       "      <td>0.848724</td>\n",
       "      <td>-0.435613</td>\n",
       "      <td>0.156589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82856</th>\n",
       "      <td>3644</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>309.330048</td>\n",
       "      <td>0.848724</td>\n",
       "      <td>-0.435613</td>\n",
       "      <td>0.156589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82857</th>\n",
       "      <td>3645</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>309.330048</td>\n",
       "      <td>0.848724</td>\n",
       "      <td>-0.435613</td>\n",
       "      <td>0.156589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82858</th>\n",
       "      <td>3646</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>309.330048</td>\n",
       "      <td>0.848724</td>\n",
       "      <td>-0.435613</td>\n",
       "      <td>0.156589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141141555</th>\n",
       "      <td>12175</td>\n",
       "      <td>10690</td>\n",
       "      <td>5</td>\n",
       "      <td>311.829102</td>\n",
       "      <td>0.529260</td>\n",
       "      <td>-0.115972</td>\n",
       "      <td>0.162138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141141556</th>\n",
       "      <td>12176</td>\n",
       "      <td>10690</td>\n",
       "      <td>5</td>\n",
       "      <td>311.829102</td>\n",
       "      <td>0.529260</td>\n",
       "      <td>-0.115972</td>\n",
       "      <td>0.162138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141141557</th>\n",
       "      <td>12177</td>\n",
       "      <td>10690</td>\n",
       "      <td>5</td>\n",
       "      <td>311.308105</td>\n",
       "      <td>0.568186</td>\n",
       "      <td>-0.153507</td>\n",
       "      <td>0.158356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141141558</th>\n",
       "      <td>12178</td>\n",
       "      <td>10690</td>\n",
       "      <td>5</td>\n",
       "      <td>311.308105</td>\n",
       "      <td>0.568186</td>\n",
       "      <td>-0.153507</td>\n",
       "      <td>0.158356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141141559</th>\n",
       "      <td>12179</td>\n",
       "      <td>10690</td>\n",
       "      <td>5</td>\n",
       "      <td>311.308105</td>\n",
       "      <td>0.568186</td>\n",
       "      <td>-0.153507</td>\n",
       "      <td>0.158356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63008537 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               x      y  landcover         lst      ndvi      ndbi    albedo\n",
       "82854       3642      6          6  309.330048  0.848724 -0.435613  0.156589\n",
       "82855       3643      6          6  309.330048  0.848724 -0.435613  0.156589\n",
       "82856       3644      6          6  309.330048  0.848724 -0.435613  0.156589\n",
       "82857       3645      6          6  309.330048  0.848724 -0.435613  0.156589\n",
       "82858       3646      6          6  309.330048  0.848724 -0.435613  0.156589\n",
       "...          ...    ...        ...         ...       ...       ...       ...\n",
       "141141555  12175  10690          5  311.829102  0.529260 -0.115972  0.162138\n",
       "141141556  12176  10690          5  311.829102  0.529260 -0.115972  0.162138\n",
       "141141557  12177  10690          5  311.308105  0.568186 -0.153507  0.158356\n",
       "141141558  12178  10690          5  311.308105  0.568186 -0.153507  0.158356\n",
       "141141559  12179  10690          5  311.308105  0.568186 -0.153507  0.158356\n",
       "\n",
       "[63008537 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df = predict_df.loc[\n",
    "    (predict_df['landcover'] != LC_NO_DATA) & (predict_df['lst'] != 0) & (predict_df['ndvi'] != 0)\n",
    "]\n",
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1ecc275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving predict in training_samples/MILANO_predict_feb16_50mil.csv\n"
     ]
    }
   ],
   "source": [
    "predict_path = f'{samples_base_path}/{city}_predict{sufix}.csv'\n",
    "print(f'Saving predict in {predict_path}')\n",
    "predict_df = predict_df.reset_index(drop=True)\n",
    "\n",
    "predict_df.to_csv(predict_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
