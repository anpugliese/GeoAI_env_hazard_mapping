{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0b2e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "#Defining libraries\n",
    "import os\n",
    "import math\n",
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import plotly.graph_objects as go\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from shapely.geometry import box\n",
    "from scipy.interpolate import griddata, interpn\n",
    "import datacube\n",
    "from copy import deepcopy\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import matplotlib.pyplot as plt\n",
    "import rioxarray as rxr\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from modules import processing_module as processing\n",
    "from modules import ai_module as ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90710e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the Urban atlas classes (Corine 2018 classes) \n",
    "#  to 5 classes (Urban, Rural, Vegetation, Water, and Bareland)\n",
    "\"\"\"\n",
    "11100 Continuous Urban Fabric (S.L. &amp;gt; 80%)\n",
    "11210 Discontinuous Dense Urban Fabric (S.L. : 50% - 80%)\n",
    "11220 Discontinuous Medium Density Urban Fabric (S.L. : 30% - 50%)\n",
    "11230 Discontinuous Low Density Urban Fabric (S.L. : 10% - 30%)\n",
    "11240 Discontinuous Very Low Density Urban Fabric (S.L. &amp;lt; 10%)\n",
    "11300 Isolated Structures\n",
    "12100 Industrial, commercial, public, military and private units\n",
    "12210 Fast transit roads and associated land\n",
    "12220 Other roads and associated land\n",
    "12230 Railways and associated land\n",
    "12300 Port areas\n",
    "12400 Airports\n",
    "13100 Mineral extraction and dump sites\n",
    "13300 Construction sites\n",
    "13400 Land without current use\n",
    "14100 Green urban areas\n",
    "14200 Sports and leisure facilities\n",
    "\n",
    "21000 Arable land (annual crops)\n",
    "22000 Permanent crops (vineyards, fruit trees, olive groves)\n",
    "23000 Pastures\n",
    "24000 Complex and mixed cultivation patterns\n",
    "25000 Orchards at the fringe of urban classes\n",
    "\n",
    "31000 Forests\n",
    "32000 Herbaceous vegetation associations (natural grassland, moors...)\n",
    "33000 Open spaces with little or no vegetations (beaches, dunes, bare rocks, glaciers)\n",
    "\n",
    "40000 Wetland\n",
    "\n",
    "50000 Water bodies    \n",
    "\"\"\"\n",
    "\n",
    "#Convert from copernicus code 2018 to an internal code\n",
    "URBAN = 1\n",
    "RURAL = 2\n",
    "VEGETATION = 3\n",
    "WATER = 4\n",
    "BARELAND = 5\n",
    "def map_urban_atlas_class(code_18):\n",
    "    if code_18 == -9999: return -9999\n",
    "    if code_18 == 11100: return URBAN\n",
    "    if code_18 == 11210: return URBAN\n",
    "    if code_18 == 11220: return URBAN\n",
    "    if code_18 == 11230: return URBAN\n",
    "    if code_18 == 11240: return URBAN\n",
    "    if code_18 == 11300: return URBAN\n",
    "    if code_18 == 12100: return URBAN\n",
    "    if code_18 == 12210: return URBAN\n",
    "    if code_18 == 12220: return URBAN\n",
    "    if code_18 == 12230: return URBAN\n",
    "    if code_18 == 12300: return URBAN\n",
    "    if code_18 == 12400: return URBAN\n",
    "    if code_18 == 13100: return URBAN\n",
    "    if code_18 == 13300: return URBAN\n",
    "    if code_18 == 13400: return URBAN\n",
    "    if code_18 == 14100: return URBAN\n",
    "    if code_18 == 14200: return URBAN\n",
    "    \n",
    "    if code_18 == 21000: return RURAL\n",
    "    if code_18 == 22000: return RURAL\n",
    "    if code_18 == 23000: return RURAL\n",
    "    if code_18 == 24000: return RURAL\n",
    "    if code_18 == 25000: return RURAL\n",
    "    \n",
    "    if code_18 == 31000: return VEGETATION\n",
    "    if code_18 == 32000: return VEGETATION\n",
    "    if code_18 == 33000: return BARELAND\n",
    "    \n",
    "    if code_18 == 40000: return WATER\n",
    "    if code_18 == 50000: return WATER\n",
    "    \n",
    "    return -9999\n",
    "    \n",
    "# Function to check if the file is a tiff and must be read.\n",
    "def check_wrong_files(file_name):\n",
    "    if f == 'clip': return True #avoid entering the \"clip\" folder\n",
    "    if 'ipynb' in f: return True #avoid entering the \"ipynb_checkpoint\" file\n",
    "    if 'tar' in f: return True #avoid entering \"tar\" files\n",
    "    if 'aux' in f: return True #avoid entering \"aux\" files\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05d7bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_from_odc(odc_datasets, samples, x=None, y=None):\n",
    "    odc_df = None\n",
    "    for df_name in odc_datasets:\n",
    "        print(f\"Sampling {df_name}\")\n",
    "        #odc datasets to be merged\n",
    "        odc_product = df_name\n",
    "\n",
    "        datasets = dc.find_datasets(product=odc_product)\n",
    "        cf_data = dc.load(datasets=datasets)\n",
    "        if x is not None and y is not None:\n",
    "            cf_sel = cf_data.squeeze().sel(\n",
    "                y=y, \n",
    "                x=x, \n",
    "                method='nearest'\n",
    "            )\n",
    "        else:\n",
    "            cf_sel = cf_data.squeeze()\n",
    "\n",
    "        cf_var_name = list(cf_data.data_vars.keys())[0]\n",
    "        cf_df = cf_sel.to_dataframe()\n",
    "        del cf_sel\n",
    "        \n",
    "        cf_df.rename(columns={cf_var_name:odc_product},inplace=True)\n",
    "        cf_df.drop(['time','spatial_ref'],axis=1,inplace=True)\n",
    "        if 'x' in list(cf_df.columns): cf_df.drop(['x'],axis=1,inplace=True)\n",
    "        if 'y' in list(cf_df.columns): cf_df.drop(['y'],axis=1,inplace=True)\n",
    "\n",
    "        del cf_data\n",
    "        \n",
    "        if odc_df is None:\n",
    "            odc_df = cf_df.copy()\n",
    "            print(len(samples), len(odc_df))\n",
    "            odc_df = pd.concat([samples, odc_df], axis=1)\n",
    "        else:\n",
    "            odc_df = pd.concat([odc_df, cf_df[odc_product].astype('float32')], axis=1)\n",
    "\n",
    "    odc_df = odc_df.dropna()\n",
    "\n",
    "    print('odc_df Ready!')\n",
    "    return odc_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4294f015",
   "metadata": {},
   "outputs": [],
   "source": [
    "city = \"MILANO\"\n",
    "city_epsg = 32632\n",
    "data_folder = \"data\"\n",
    "landcover_path = f\"{data_folder}/MILANO_landcover.tif\"\n",
    "encode = True\n",
    "normalize = True\n",
    "train_model = False\n",
    "model = 'ANN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "606749a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accelerazione_suolo\n",
      "aspect\n",
      "building_height\n",
      "corine_urban_atlas_milan\n",
      "densita_popolazione\n",
      "dtm_milan\n",
      "dusaf\n",
      "dusaf15\n",
      "dusaf99\n",
      "fattori_amplificazione\n",
      "flood_extent\n",
      "flood_extent_year\n",
      "geologia\n",
      "hillshade\n",
      "ixelles_dem\n",
      "ixelles_distance_to_roads\n",
      "ixelles_distance_to_tracks\n",
      "ixelles_distance_to_water\n",
      "ixelles_imperviousness\n",
      "ixelles_landcover\n",
      "ixelles_population\n",
      "ixelles_slope\n",
      "litologia_superficiale\n",
      "main_road_distance\n",
      "metropolitana\n",
      "ndvi_2000\n",
      "ndvi_2002\n",
      "ndvi_2014\n",
      "ndvi_2019\n",
      "piezometrie_profondo\n",
      "piezometrie_superficiale\n",
      "piraeus_building_height\n",
      "piraeus_dem\n",
      "piraeus_distance_to_roads\n",
      "piraeus_distance_to_tracks\n",
      "piraeus_imperviousness\n",
      "piraeus_landcover\n",
      "piraeus_landcover_for_uhi\n",
      "piraeus_population\n",
      "piraeus_slope\n",
      "plan_curvature\n",
      "profile_curvature\n",
      "reticolo_idrografico\n",
      "river_distance\n",
      "sabbie_falda\n",
      "slope\n",
      "sofia_building_height\n",
      "sofia_dem\n",
      "sofia_distance_to_road\n",
      "sofia_distance_to_train_tracks\n",
      "sofia_distance_to_water\n",
      "sofia_imperviousness\n",
      "sofia_landcover\n",
      "sofia_population\n",
      "sofia_slope\n",
      "soggiacenza_falda\n",
      "spi\n",
      "strade_ferrovie\n",
      "temperatura_superficiale\n",
      "tri\n",
      "twi\n",
      "uhi_binary\n",
      "water_distance\n"
     ]
    }
   ],
   "source": [
    "#Example of datacube config file:\n",
    "#datacube_config_path = \"/home/user/datacube.conf\"\n",
    "\n",
    "datacube_config_path = \"/home/user/datacube.conf\"\n",
    "dc = datacube.Datacube(app = \"my_app\", config = datacube_config_path)\n",
    "products = dc.list_products()\n",
    "for p in products.name.values:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9a54194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The datasets from the ODC from which data is sampled\n",
    "odc_datasets = [\n",
    "    'building_height', 'densita_popolazione',\n",
    "    'main_road_distance', 'river_distance', \n",
    "    'water_distance'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf0b4fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>landcover</th>\n",
       "      <th>uhi</th>\n",
       "      <th>ndvi</th>\n",
       "      <th>lst</th>\n",
       "      <th>raster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>504755.0</td>\n",
       "      <td>5044760.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.340190</td>\n",
       "      <td>305.97598</td>\n",
       "      <td>20180815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>527405.0</td>\n",
       "      <td>5032805.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.365114</td>\n",
       "      <td>304.33533</td>\n",
       "      <td>20180815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>512730.0</td>\n",
       "      <td>5026165.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.485528</td>\n",
       "      <td>305.89053</td>\n",
       "      <td>20180815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>516430.0</td>\n",
       "      <td>5043370.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.337092</td>\n",
       "      <td>304.33533</td>\n",
       "      <td>20180815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>524665.0</td>\n",
       "      <td>5040390.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.405153</td>\n",
       "      <td>305.80850</td>\n",
       "      <td>20180815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099995</th>\n",
       "      <td>525765.0</td>\n",
       "      <td>5031595.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.373092</td>\n",
       "      <td>306.35880</td>\n",
       "      <td>20200719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099996</th>\n",
       "      <td>512985.0</td>\n",
       "      <td>5029820.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.324245</td>\n",
       "      <td>311.44140</td>\n",
       "      <td>20200719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099997</th>\n",
       "      <td>512790.0</td>\n",
       "      <td>5024110.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.286099</td>\n",
       "      <td>308.65570</td>\n",
       "      <td>20200719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099998</th>\n",
       "      <td>498990.0</td>\n",
       "      <td>5031685.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.471453</td>\n",
       "      <td>305.72305</td>\n",
       "      <td>20200719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099999</th>\n",
       "      <td>538285.0</td>\n",
       "      <td>5048680.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.336419</td>\n",
       "      <td>312.43262</td>\n",
       "      <td>20200719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                x          y  landcover  uhi      ndvi        lst    raster\n",
       "0        504755.0  5044760.0          1    0  0.340190  305.97598  20180815\n",
       "1        527405.0  5032805.0          1    0  0.365114  304.33533  20180815\n",
       "2        512730.0  5026165.0          1    0  0.485528  305.89053  20180815\n",
       "3        516430.0  5043370.0          1    0  0.337092  304.33533  20180815\n",
       "4        524665.0  5040390.0          1    0  0.405153  305.80850  20180815\n",
       "...           ...        ...        ...  ...       ...        ...       ...\n",
       "1099995  525765.0  5031595.0          2    1  0.373092  306.35880  20200719\n",
       "1099996  512985.0  5029820.0          2    1  0.324245  311.44140  20200719\n",
       "1099997  512790.0  5024110.0          2    1  0.286099  308.65570  20200719\n",
       "1099998  498990.0  5031685.0          2    1  0.471453  305.72305  20200719\n",
       "1099999  538285.0  5048680.0          2    1  0.336419  312.43262  20200719\n",
       "\n",
       "[1100000 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importer = processing.HarmoniaProcessor()\n",
    "\n",
    "# get raster parameters\n",
    "with rasterio.open(landcover_path, driver=\"GTiff\") as base_raster:\n",
    "    transform = base_raster.transform\n",
    "    init_x = transform[2]\n",
    "    init_y = transform[5]\n",
    "    step_x = transform[0]\n",
    "    step_y = transform[4]\n",
    "\n",
    "#import samples\n",
    "base_path = f'training_samples'\n",
    "samples_path = f'{base_path}/{city}_samples.csv'\n",
    "samples = importer.import_df(samples_path, date_format=None)\n",
    "\n",
    "samples['x'] = samples['x'].apply(\n",
    "    lambda x: init_x + (x * step_x)\n",
    ")\n",
    "samples['y'] = samples['y'].apply(\n",
    "    lambda y: init_y + (y * step_y)\n",
    ")\n",
    "samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e0f1b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling building_height\n",
      "1100000 1083227\n",
      "Sampling densita_popolazione\n",
      "Sampling main_road_distance\n",
      "Sampling river_distance\n",
      "Sampling water_distance\n",
      "odc_df Ready!\n",
      "ready\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>landcover</th>\n",
       "      <th>uhi</th>\n",
       "      <th>ndvi</th>\n",
       "      <th>lst</th>\n",
       "      <th>raster</th>\n",
       "      <th>building_height</th>\n",
       "      <th>densita_popolazione</th>\n",
       "      <th>main_road_distance</th>\n",
       "      <th>river_distance</th>\n",
       "      <th>water_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>504755.0</td>\n",
       "      <td>5044760.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.340190</td>\n",
       "      <td>305.975983</td>\n",
       "      <td>20180815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>749.016052</td>\n",
       "      <td>94.339813</td>\n",
       "      <td>94.339813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>527405.0</td>\n",
       "      <td>5032805.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.365114</td>\n",
       "      <td>304.335327</td>\n",
       "      <td>20180815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>138.293167</td>\n",
       "      <td>138.293167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>512730.0</td>\n",
       "      <td>5026165.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.485528</td>\n",
       "      <td>305.890533</td>\n",
       "      <td>20180815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>93.941467</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>516430.0</td>\n",
       "      <td>5043370.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.337092</td>\n",
       "      <td>304.335327</td>\n",
       "      <td>20180815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>526.165405</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>524665.0</td>\n",
       "      <td>5040390.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.405153</td>\n",
       "      <td>305.808502</td>\n",
       "      <td>20180815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>320.663391</td>\n",
       "      <td>55.226803</td>\n",
       "      <td>55.226803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083222</th>\n",
       "      <td>508730.0</td>\n",
       "      <td>5022140.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.264716</td>\n",
       "      <td>309.838348</td>\n",
       "      <td>20200719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>336.823395</td>\n",
       "      <td>187.416656</td>\n",
       "      <td>187.416656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083223</th>\n",
       "      <td>526985.0</td>\n",
       "      <td>5024355.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.107714</td>\n",
       "      <td>322.122711</td>\n",
       "      <td>20200719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>511.590637</td>\n",
       "      <td>46.097721</td>\n",
       "      <td>46.097721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083224</th>\n",
       "      <td>502505.0</td>\n",
       "      <td>5044070.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.188039</td>\n",
       "      <td>313.461456</td>\n",
       "      <td>20200719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>919.959229</td>\n",
       "      <td>191.637695</td>\n",
       "      <td>191.637695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083225</th>\n",
       "      <td>489140.0</td>\n",
       "      <td>5039245.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.444726</td>\n",
       "      <td>305.846100</td>\n",
       "      <td>20200719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>99.624290</td>\n",
       "      <td>14.142136</td>\n",
       "      <td>14.142136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083226</th>\n",
       "      <td>502505.0</td>\n",
       "      <td>5047930.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.358886</td>\n",
       "      <td>305.774323</td>\n",
       "      <td>20200719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>288.617401</td>\n",
       "      <td>514.635803</td>\n",
       "      <td>514.635803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1079540 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                x          y  landcover  uhi      ndvi         lst    raster  \\\n",
       "0        504755.0  5044760.0          1    0  0.340190  305.975983  20180815   \n",
       "1        527405.0  5032805.0          1    0  0.365114  304.335327  20180815   \n",
       "2        512730.0  5026165.0          1    0  0.485528  305.890533  20180815   \n",
       "3        516430.0  5043370.0          1    0  0.337092  304.335327  20180815   \n",
       "4        524665.0  5040390.0          1    0  0.405153  305.808502  20180815   \n",
       "...           ...        ...        ...  ...       ...         ...       ...   \n",
       "1083222  508730.0  5022140.0          2    1  0.264716  309.838348  20200719   \n",
       "1083223  526985.0  5024355.0          2    1  0.107714  322.122711  20200719   \n",
       "1083224  502505.0  5044070.0          2    1  0.188039  313.461456  20200719   \n",
       "1083225  489140.0  5039245.0          2    1  0.444726  305.846100  20200719   \n",
       "1083226  502505.0  5047930.0          2    1  0.358886  305.774323  20200719   \n",
       "\n",
       "         building_height  densita_popolazione  main_road_distance  \\\n",
       "0                    0.0                0.000          749.016052   \n",
       "1                    0.0                0.000           10.000000   \n",
       "2                    0.0                0.000           93.941467   \n",
       "3                    0.0                0.000          526.165405   \n",
       "4                    0.0                0.000          320.663391   \n",
       "...                  ...                  ...                 ...   \n",
       "1083222              0.0                0.000          336.823395   \n",
       "1083223              0.0                0.000          511.590637   \n",
       "1083224              0.0                0.000          919.959229   \n",
       "1083225              0.0                0.000           99.624290   \n",
       "1083226              0.0                0.003          288.617401   \n",
       "\n",
       "         river_distance  water_distance  \n",
       "0             94.339813       94.339813  \n",
       "1            138.293167      138.293167  \n",
       "2            120.000000      120.000000  \n",
       "3            150.000000      150.000000  \n",
       "4             55.226803       55.226803  \n",
       "...                 ...             ...  \n",
       "1083222      187.416656      187.416656  \n",
       "1083223       46.097721       46.097721  \n",
       "1083224      191.637695      191.637695  \n",
       "1083225       14.142136       14.142136  \n",
       "1083226      514.635803      514.635803  \n",
       "\n",
       "[1079540 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_positions = samples.drop_duplicates(subset=['x', 'y']).reset_index(drop=True)[['x','y']]\n",
    "single_x_positions = single_positions.x.values\n",
    "single_y_positions = single_positions.y.values\n",
    "\n",
    "odc_df = fetch_from_odc(\n",
    "    odc_datasets, \n",
    "    samples,\n",
    "    x=xr.DataArray(single_x_positions, dims=['index']),\n",
    "    y=xr.DataArray(single_y_positions, dims=['index'])\n",
    ")\n",
    "\n",
    "# set UHI column as integer\n",
    "odc_df['uhi'] = odc_df['uhi'].apply(\n",
    "    lambda x: int(x),\n",
    ").astype('int8')\n",
    "\n",
    "#coordinates as float32 to reduce size in disk\n",
    "odc_df['x'] = odc_df['x'].astype('float64')\n",
    "odc_df['y'] = odc_df['y'].astype('float64')\n",
    "odc_df['lst'] = odc_df['lst'].astype('float32')\n",
    "odc_df['ndvi'] = odc_df['ndvi'].astype('float32')\n",
    "odc_df['landcover'] = odc_df['landcover'].astype('int32')\n",
    "odc_df['uhi'] = odc_df['uhi'].astype('uint8')\n",
    "\n",
    "print(\"ready\")\n",
    "odc_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7f3067f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uhi</th>\n",
       "      <th>ndvi</th>\n",
       "      <th>lst</th>\n",
       "      <th>building_height</th>\n",
       "      <th>densita_popolazione</th>\n",
       "      <th>main_road_distance</th>\n",
       "      <th>river_distance</th>\n",
       "      <th>water_distance</th>\n",
       "      <th>landcover_landcover_1</th>\n",
       "      <th>landcover_landcover_2</th>\n",
       "      <th>landcover_landcover_3</th>\n",
       "      <th>landcover_landcover_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.340190</td>\n",
       "      <td>305.975983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>749.016052</td>\n",
       "      <td>94.339813</td>\n",
       "      <td>94.339813</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.365114</td>\n",
       "      <td>304.335327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>138.293167</td>\n",
       "      <td>138.293167</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.485528</td>\n",
       "      <td>305.890533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.941467</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.337092</td>\n",
       "      <td>304.335327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>526.165405</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.405153</td>\n",
       "      <td>305.808502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>320.663391</td>\n",
       "      <td>55.226803</td>\n",
       "      <td>55.226803</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079535</th>\n",
       "      <td>1</td>\n",
       "      <td>0.502171</td>\n",
       "      <td>306.970642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>326.840942</td>\n",
       "      <td>41.231056</td>\n",
       "      <td>41.231056</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079536</th>\n",
       "      <td>1</td>\n",
       "      <td>0.377483</td>\n",
       "      <td>312.135254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>1937.588623</td>\n",
       "      <td>1937.588623</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079537</th>\n",
       "      <td>1</td>\n",
       "      <td>0.215878</td>\n",
       "      <td>311.796875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.951355</td>\n",
       "      <td>36.400551</td>\n",
       "      <td>36.400551</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079538</th>\n",
       "      <td>1</td>\n",
       "      <td>0.183535</td>\n",
       "      <td>316.510315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.056938</td>\n",
       "      <td>26.925823</td>\n",
       "      <td>26.925823</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079539</th>\n",
       "      <td>1</td>\n",
       "      <td>0.262900</td>\n",
       "      <td>313.287140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.591415</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1075866 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         uhi      ndvi         lst  building_height  densita_popolazione  \\\n",
       "0          0  0.340190  305.975983              0.0                  0.0   \n",
       "1          0  0.365114  304.335327              0.0                  0.0   \n",
       "2          0  0.485528  305.890533              0.0                  0.0   \n",
       "3          0  0.337092  304.335327              0.0                  0.0   \n",
       "4          0  0.405153  305.808502              0.0                  0.0   \n",
       "...      ...       ...         ...              ...                  ...   \n",
       "1079535    1  0.502171  306.970642              0.0                  0.0   \n",
       "1079536    1  0.377483  312.135254              0.0                  0.0   \n",
       "1079537    1  0.215878  311.796875              0.0                  0.0   \n",
       "1079538    1  0.183535  316.510315              0.0                  0.0   \n",
       "1079539    1  0.262900  313.287140              0.0                  0.0   \n",
       "\n",
       "         main_road_distance  river_distance  water_distance  \\\n",
       "0                749.016052       94.339813       94.339813   \n",
       "1                 10.000000      138.293167      138.293167   \n",
       "2                 93.941467      120.000000      120.000000   \n",
       "3                526.165405      150.000000      150.000000   \n",
       "4                320.663391       55.226803       55.226803   \n",
       "...                     ...             ...             ...   \n",
       "1079535          326.840942       41.231056       41.231056   \n",
       "1079536          150.000000     1937.588623     1937.588623   \n",
       "1079537         1017.951355       36.400551       36.400551   \n",
       "1079538           79.056938       26.925823       26.925823   \n",
       "1079539          102.591415       10.000000       10.000000   \n",
       "\n",
       "         landcover_landcover_1  landcover_landcover_2  landcover_landcover_3  \\\n",
       "0                            1                      0                      0   \n",
       "1                            1                      0                      0   \n",
       "2                            1                      0                      0   \n",
       "3                            1                      0                      0   \n",
       "4                            1                      0                      0   \n",
       "...                        ...                    ...                    ...   \n",
       "1079535                      0                      1                      0   \n",
       "1079536                      0                      1                      0   \n",
       "1079537                      0                      1                      0   \n",
       "1079538                      0                      1                      0   \n",
       "1079539                      0                      1                      0   \n",
       "\n",
       "         landcover_landcover_5  \n",
       "0                            0  \n",
       "1                            0  \n",
       "2                            0  \n",
       "3                            0  \n",
       "4                            0  \n",
       "...                        ...  \n",
       "1079535                      0  \n",
       "1079536                      0  \n",
       "1079537                      0  \n",
       "1079538                      0  \n",
       "1079539                      0  \n",
       "\n",
       "[1075866 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encode Columns\n",
    "train_df = odc_df.copy()\n",
    "if encode:\n",
    "    #encode categorical columns\n",
    "    encoding_columns = ['landcover']\n",
    "    encoders = {\n",
    "        \"landcover\": OneHotEncoder(sparse=False, dtype='uint16', handle_unknown='ignore')\n",
    "    }\n",
    "\n",
    "    for enc in encoding_columns:\n",
    "        enc_list = train_df[enc].values.reshape(-1, 1)\n",
    "        encoded_data = encoders[enc].fit_transform(enc_list)\n",
    "\n",
    "        encoded_columns = [f\"{enc}_{category}\" for category in encoders[enc].get_feature_names_out([enc])]\n",
    "        train_df = pd.concat(\n",
    "            [train_df, pd.DataFrame(encoded_data, columns=encoded_columns, dtype='int32')], \n",
    "            axis=1,\n",
    "            join='inner'\n",
    "        )\n",
    "        train_df = train_df.drop(columns=[enc])\n",
    "\n",
    "    train_df = train_df.dropna()\n",
    "\n",
    "    #drop resulting _nan columns\n",
    "    _nan_columns = list(filter(lambda x: '_nan' in x, list(train_df.columns)))\n",
    "    train_df = train_df.drop(columns=_nan_columns)\n",
    "\n",
    "    \n",
    "#drop raster, x, and y columns\n",
    "train_df_complete = train_df.drop(columns=['raster','x','y'])\n",
    "\n",
    "for col in odc_datasets:\n",
    "    train_df_complete = train_df_complete.loc[\n",
    "        train_df_complete[col] != -9999\n",
    "    ]\n",
    "\n",
    "train_df_complete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da5dea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare data for model and normalize\n",
    "train_df = train_df_complete.copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df.drop('uhi', axis=1), train_df['uhi'], test_size=0.7, random_state=42, stratify=train_df['uhi'])\n",
    "\n",
    "columns_list = list(X_train.columns)\n",
    "X_train_df = pd.DataFrame(X_train, columns=columns_list)\n",
    "X_test_df = pd.DataFrame(X_test, columns=columns_list)\n",
    "\n",
    "scaler = None\n",
    "if normalize:    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "ai_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f95eb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scaler.pkl','wb') as f:\n",
    "    pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e46bdd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 0 ns, total: 1e+03 ns\n",
      "Wall time: 2.86 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if train_model:\n",
    "    if model == 'RF':\n",
    "        #Random forest Model\n",
    "        ai_model = RandomForestClassifier(\n",
    "            n_estimators = 1000, \n",
    "            max_depth=7,\n",
    "            random_state = 42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        ai_model.fit(X_train, y_train)\n",
    "\n",
    "        score = ai_model.score(X_test, y_test)\n",
    "        print(f'Score for RF: {score}')\n",
    "\n",
    "    elif model == 'ANN':\n",
    "\n",
    "        hidden_layer_sizes = (30,20,2)\n",
    "        ai_model = MLPClassifier(\n",
    "            solver='adam', \n",
    "            activation='relu',\n",
    "            alpha=1e-6, \n",
    "            hidden_layer_sizes=hidden_layer_sizes,         \n",
    "            max_iter=10000,\n",
    "            batch_size=200,\n",
    "            learning_rate='constant',\n",
    "\n",
    "            random_state=42,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        ai_model.fit(X_train, y_train)\n",
    "\n",
    "        score = ai_model.score(X_test, y_test)\n",
    "        print(f'Score for ANN: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c059ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    if model == 'RF':\n",
    "        columns_list = list(X_train_df.columns)\n",
    "        importances = pd.DataFrame(ai_model.feature_importances_)\n",
    "        importances['label'] = pd.Series(X_train_df.columns.values)\n",
    "        importances = importances.sort_values(by=0, ascending=False).reset_index(drop=True)\n",
    "        importer.show_plot(importances, 'label', 0)\n",
    "    elif model == 'ANN':\n",
    "        columns_list = list(X_train_df.columns)\n",
    "        importances = pd.DataFrame(ai_model.coef_)\n",
    "        importances['label'] = pd.Series(X_train_df.columns.values)\n",
    "        importances = importances.sort_values(by=0, ascending=False).reset_index(drop=True)\n",
    "        importer.show_plot(importances, 'label', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "751045ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_model:\n",
    "    #save model\n",
    "    model_score = str(score)[2:4]\n",
    "    model_file = f'model/model_{model}_{model_score}.pkl'\n",
    "    print(model_file)\n",
    "    with open(model_file, 'wb') as file:\n",
    "        pickle.dump(ai_model, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a240f522",
   "metadata": {},
   "source": [
    "# PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e9c8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not train_model:\n",
    "    model_score = '86'\n",
    "    # Load the trained model using pickle\n",
    "    model_file = f'model/model_{model}_86.pkl'\n",
    "    with open(model_file, 'rb') as file:\n",
    "        ai_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0d9d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the whole image\n",
    "importer = processing.HarmoniaProcessor()\n",
    "\n",
    "# get raster parameters from landcover\n",
    "with rasterio.open(landcover_path, driver=\"GTiff\") as base_raster:\n",
    "    transform = base_raster.transform\n",
    "    init_x = transform[2]\n",
    "    init_y = transform[5]\n",
    "    step_x = transform[0]\n",
    "    step_y = transform[4]\n",
    "\n",
    "#import samples\n",
    "base_path = f'training_samples'\n",
    "predict_path = f'{base_path}/{city}_predict.csv'\n",
    "predict = importer.import_df(predict_path, date_format=None)\n",
    "\n",
    "predict['lst'] = predict['lst'].astype('float32')\n",
    "predict['ndvi'] = predict['ndvi'].astype('float32')\n",
    "predict['landcover'] = predict['landcover'].astype('int32')\n",
    "predict['x'] = predict['x'].astype('float64')\n",
    "predict['y'] = predict['y'].astype('float64')\n",
    "\n",
    "predict['landcover'] = predict['landcover'].apply(map_urban_atlas_class).astype('int32')\n",
    "\n",
    "predict['x'] = predict['x'].apply(\n",
    "    lambda x: init_x + (x * step_x)\n",
    ")\n",
    "predict['y'] = predict['y'].apply(\n",
    "    lambda y: init_y + (y * step_y)\n",
    ")\n",
    "\n",
    "predict_x_positions = predict.x.values\n",
    "predict_y_positions = predict.y.values\n",
    "\n",
    "full_data_df = fetch_from_odc(\n",
    "    odc_datasets, \n",
    "    predict,\n",
    "    x=xr.DataArray(predict_x_positions, dims=['index']),\n",
    "    y=xr.DataArray(predict_y_positions, dims=['index'])\n",
    ")\n",
    "\n",
    "#remove water pixels\n",
    "full_data_df = full_data_df.loc[\n",
    "    full_data_df['landcover'] != WATER\n",
    "].reset_index(drop=True)\n",
    "print(\"ready\")\n",
    "\n",
    "#remove nodata from odc datasets\n",
    "for col in odc_datasets:\n",
    "    full_data_df = full_data_df.loc[\n",
    "        full_data_df[col] != -9999\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "full_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dda01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if encode:\n",
    "    #encode categorical columns\n",
    "    encoding_columns = ['landcover']\n",
    "    all_encoded_columns = []\n",
    "    for enc in encoding_columns:\n",
    "        enc_list = full_data_df[enc].values.reshape(-1, 1)\n",
    "        encoded_data = encoders[enc].transform(enc_list)\n",
    "\n",
    "        encoded_columns = [f\"{enc}_{category}\" for category in encoders[enc].get_feature_names_out([enc])]\n",
    "        print(encoded_columns)\n",
    "        full_data_df = pd.concat([full_data_df, pd.DataFrame(encoded_data, columns=encoded_columns)], axis=1)\n",
    "        all_encoded_columns += encoded_columns.copy()\n",
    "        full_data_df = full_data_df.drop(columns=[enc])\n",
    "\n",
    "    full_data_df = full_data_df.dropna()\n",
    "    for enc_col in all_encoded_columns:\n",
    "        full_data_df[enc_col] = full_data_df[enc_col].astype('uint16')\n",
    "\n",
    "    #drop resulting _nan columns\n",
    "    _nan_columns = list(filter(lambda x: '_nan' in x, list(full_data_df.columns)))\n",
    "    full_data_df = full_data_df.drop(columns=_nan_columns)\n",
    "\n",
    "full_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587bf945",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert all odc dataset columns to float32 to save disk\n",
    "for col in odc_datasets:\n",
    "    full_data_df[col] = full_data_df[col].astype('float32')\n",
    "\n",
    "full_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b66082",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict_df = full_data_df.copy()\n",
    "\n",
    "data_coord = pd.concat([predict_df[col] for col in ['y', 'x']], axis=1)\n",
    "predict_df = predict_df.drop(columns=['x','y'])\n",
    "\n",
    "#Fix order column for model\n",
    "column_order = [\"ndvi\",\"lst\"]\n",
    "column_order += odc_datasets\n",
    "column_order += [\"landcover_landcover_1\",\"landcover_landcover_2\",\"landcover_landcover_3\",\"landcover_landcover_5\"]\n",
    "\n",
    "predict_df = predict_df[column_order]\n",
    "\n",
    "# ignore the warnings for feature names. The important thing is that the dataset has the same order of the training one\n",
    "# to remove the warnings create a dataframe with the normalized dataset and the column list\n",
    "batch_size = 1000000\n",
    "\n",
    "if normalize:\n",
    "    full_data_predict = scaler.transform(predict_df)\n",
    "else:\n",
    "    full_data_predict = predict_df\n",
    "\n",
    "# predict probabilities in batches\n",
    "probs = []\n",
    "for i in range(0, len(full_data_predict), batch_size):\n",
    "    batch = full_data_predict[i:i+batch_size]\n",
    "    batch_probs = ai_model.predict_proba(batch)[:,1]\n",
    "    probs.append(batch_probs)\n",
    "    print(f'Done {i}')\n",
    "\n",
    "full_data_prob = np.concatenate(probs, axis=0)\n",
    "full_data_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8840f4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#append the x,y coordinates to the probabilities\n",
    "full_data_df = pd.DataFrame(full_data_prob).reset_index(drop=True)\n",
    "full_data_df['x'] = data_coord['x'].reset_index(drop=True)\n",
    "full_data_df['y'] = data_coord['y'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9b3f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_df.rename(columns={0:'probability'}, inplace=True)\n",
    "full_data_df = full_data_df.round({'probability': 4})\n",
    "full_data_df['probability'] = full_data_df['probability'].astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0175f5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'predictions'\n",
    "predictions_path = f'{base_path}/{city}_UHI_{model}_predictions_acc_{model_score}.csv'\n",
    "print(f'Saving to {predictions_path}')\n",
    "full_data_df.to_csv(predictions_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4010fb55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cubeenv",
   "language": "python",
   "name": "cubeenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
