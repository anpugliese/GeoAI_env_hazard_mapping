{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bb5bf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 14:37:29.418378: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-16 14:37:29.419786: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-16 14:37:29.442375: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-16 14:37:29.443120: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-16 14:37:29.826146: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "#Defining libraries\n",
    "import os\n",
    "import math\n",
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import plotly.graph_objects as go\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from shapely.geometry import box\n",
    "from scipy.interpolate import griddata, interpn\n",
    "import datacube\n",
    "from copy import deepcopy\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from rasterio.mask import mask\n",
    "from rasterio.windows import Window\n",
    "from rasterio.warp import reproject, Resampling\n",
    "#from rasterio.enums import Resampling\n",
    "from rasterio.transform import from_origin\n",
    "from rasterio.windows import Window\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from modules import processing_module as processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4541635a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1-11-> Residential urban areas \n",
    "2-121,13->Industrial and abbandoned urban areas\n",
    "3-122,123,124 Transportation infrastructure (streets, highways, airports, and ports)\n",
    "4-14->Urban green areas\n",
    "5-2->Agricultural areas\n",
    "6-3->Forest\n",
    "7-4/5->Hydro and humid bodies\n",
    "'''\n",
    "#Convert from copernicus code 2018 to an internal code\n",
    "URBAN = 1\n",
    "INDUSTRIAL = 2\n",
    "TRANSPORTATION = 3\n",
    "URBAN_VEGETATION = 4\n",
    "RURAL = 5\n",
    "FOREST = 6\n",
    "WATER = 7\n",
    "LC_NO_DATA = 9999\n",
    "NO_DATA= -9999\n",
    "    \n",
    "# Function to check if the file is a tiff and must be read.\n",
    "def check_wrong_files(f):\n",
    "    if f == 'clip': return True #avoid entering the \"clip\" folder\n",
    "    if 'csv'in f: return True\n",
    "    if f in ['LC08_L2SP_194028_20170524_20200903_02_T1']: return True #Not consider the 2017 image as it biases the model\n",
    "    if 'ipynb' in f: return True #avoid entering the \"ipynb_checkpoint\" file\n",
    "    if 'tar' in f: return True #avoid entering \"tar\" files\n",
    "    if 'aux' in f: return True #avoid entering \"aux\" files\n",
    "    return False\n",
    "\n",
    "def match_landsat_to_landcover(landsat):\n",
    "    year = int(landsat[17:21])\n",
    "    if year in [2015,2016]:\n",
    "        return str(2015)\n",
    "    elif year in [2017,2018,2019]:\n",
    "        return str(2018)\n",
    "    elif year in [2020,2021,2022]:\n",
    "        return str(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2b6c41d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# City parameters and global variables\n",
    "city_info = {\n",
    "    \"resolution\": 5,\n",
    "    \"epsg\": 32632,\n",
    "    \"capitalized\": \"Milan\"\n",
    "}\n",
    "\n",
    "city = 'MILANO'\n",
    "current_city_info = city_info\n",
    "city_epsg = current_city_info['epsg']\n",
    "data_folder = \"data\"\n",
    "#landcover_path = f'{landcover_base_path}/DUSAF_MCM_mapped_{year}.tif'\n",
    "\n",
    "landsat_raster_folder = \"/home/user/ODC_harmonia/Landsat/Milan/data\"\n",
    "sat_images_path = f\"{landsat_raster_folder}/clip\"\n",
    "file_list = os.listdir(f\"{sat_images_path}\")\n",
    "landcover_base_path = f'{data_folder}/landcover'\n",
    "#landsat_raster_file_list = os.listdir(f\"{landsat_raster_folder}\")\n",
    "\n",
    "total_samples_per_raster = 50000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bec494b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lst = None\n",
    "predict_ndvi = None\n",
    "predict_ndbi = None\n",
    "predict_albedo = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e62a5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23814686",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing LC08_L2SP_194028_20180815_20200831_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20190717_20200827_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20190818_20200827_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20150722_20200908_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20180730_20200831_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20220725_20220802_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20220709_20220721_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20210706_20210713_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20200820_20200905_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20220810_20220818_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20160622_20200906_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20150807_20200909_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20210722_20210729_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20150706_20200909_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20160825_20200906_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n",
      "Processing LC08_L2SP_194028_20200719_20200911_02_T1\n",
      "Read land cover\n",
      "read UHI\n",
      "read UHII\n",
      "read NDVI\n",
      "read NDBI\n",
      "read albedo\n",
      "read LST\n"
     ]
    }
   ],
   "source": [
    "#Commented out for legacy\n",
    "'''\n",
    "samples = pd.DataFrame()\n",
    "predict_n = 0\n",
    "predict_lst = None\n",
    "predict_ndvi = None\n",
    "predict_ndbi = None\n",
    "predict_albedo = None\n",
    "\n",
    "sample_n = [\n",
    "    int(total_samples_per_raster / 4), # urban, uhi 1\n",
    "    int(total_samples_per_raster / 4), # urban, uhi 0\n",
    "    int(total_samples_per_raster / 4), # rural/vegetation/bareland, uhi 1\n",
    "    int(total_samples_per_raster / 4), # rural/vegetation/bareland, uhi 0\n",
    "]\n",
    "\n",
    "for f in file_list:\n",
    "    if check_wrong_files(f): continue\n",
    "\n",
    "    print(f'Processing {f}')\n",
    "    file_date_string = f.split('_')[3] #example: LC08_L2SP_194028_20160825_20200906_02_T1_LST\n",
    "    year = match_landsat_to_landcover(f)\n",
    "    landcover_path = f'{landcover_base_path}/DUSAF_{year}_MCM_mapped.tif'\n",
    "    \n",
    "    with rasterio.open(landcover_path, driver=\"GTiff\") as landcover_raster:\n",
    "        landcover_array = landcover_raster.read(1)\n",
    "        #print(landcover_raster.profile)\n",
    "        print('Read land cover')\n",
    "        rows, cols = landcover_array.shape\n",
    "        x_positions = np.arange(0, cols)\n",
    "        y_positions = np.arange(0, rows)\n",
    "        x, y = np.meshgrid(x_positions, y_positions)\n",
    "        x_flat = x.flatten()\n",
    "        y_flat = y.flatten()\n",
    "        values_flat = landcover_array.flatten()\n",
    "\n",
    "        # Create a DataFrame for the Landcover \n",
    "        landcover_df = pd.DataFrame({'x': x_flat, 'y': y_flat, 'landcover': values_flat})\n",
    "        landcover_df['landcover'] = landcover_df['landcover']\n",
    "    if not isinstance(predict_lst,np.ndarray) and not isinstance(predict_ndvi,np.ndarray) and not isinstance(predict_ndbi,np.ndarray) and not isinstance(predict_albedo,np.ndarray):\n",
    "        predict_lst = np.zeros_like(landcover_array)\n",
    "        predict_ndvi = np.zeros_like(landcover_array)\n",
    "        predict_ndbi = np.zeros_like(landcover_array)\n",
    "        predict_albedo = np.zeros_like(landcover_array)\n",
    "\n",
    "    #columns in the end: x,y,landcover,ndvi,raster\n",
    "    train_df = landcover_df.copy()\n",
    "\n",
    "    #add the uhi column\n",
    "    with rasterio.open(f\"{sat_images_path}/{f}/{f}_uhi.tif\", driver=\"GTiff\") as uhi_raster:\n",
    "        print('read UHI')\n",
    "        uhi_array = uhi_raster.read(1) #UHI band\n",
    "        uhi_flat = uhi_array.flatten()\n",
    "        train_df['uhi'] = pd.Series(uhi_flat).astype('int16')\n",
    "\n",
    "    #add the uhi intensity column\n",
    "    #Uncomment to switch to UHI Intensity instead of UHI binary\n",
    "    \n",
    "    with rasterio.open(f\"{sat_images_path}/{f}/{f}_uhi_int.tif\", driver=\"GTiff\") as uhii_raster:\n",
    "        print('read UHII')\n",
    "        uhii_array = uhii_raster.read(1) #UHI band\n",
    "        uhii_flat = uhii_array.flatten()\n",
    "        train_df['uhii'] = pd.Series(uhii_flat).astype('float32')\n",
    "    \n",
    "    #add the ndvi column\n",
    "    with rasterio.open(f\"{sat_images_path}/{f}/{f}_NDVI.TIF\", driver=\"GTiff\") as ndvi_raster:\n",
    "        print('read NDVI')\n",
    "        ndvi_array = ndvi_raster.read(1) #UHI band\n",
    "        ndvi_flat = ndvi_array.flatten()\n",
    "        train_df['ndvi'] = pd.Series(ndvi_flat).astype('float32')\n",
    "    \n",
    "    #add the ndbi column\n",
    "    with rasterio.open(f\"{sat_images_path}/{f}/{f}_NDBI.TIF\", driver=\"GTiff\") as ndbi_raster:\n",
    "        print('read NDBI')\n",
    "        ndbi_array = ndbi_raster.read(1) #UHI band\n",
    "        ndbi_flat = ndbi_array.flatten()\n",
    "        train_df['ndbi'] = pd.Series(ndbi_flat).astype('float32')\n",
    "    \n",
    "    #add the albedo column\n",
    "    with rasterio.open(f\"{sat_images_path}/{f}/{f}_albedo.TIF\", driver=\"GTiff\") as albedo_raster:\n",
    "        print('read albedo')\n",
    "        albedo_array = albedo_raster.read(1) #UHI band\n",
    "        albedo_flat = albedo_array.flatten()\n",
    "        train_df['albedo'] = pd.Series(albedo_flat).astype('float32')\n",
    "\n",
    "    #add the LST column\n",
    "    with rasterio.open(f\"{sat_images_path}/{f}/{f}_LST.TIF\", driver=\"GTiff\") as lst_raster:\n",
    "        print('read LST')\n",
    "        lst_array = lst_raster.read(1) #UHI band\n",
    "        lst_flat = lst_array.flatten()\n",
    "        train_df['lst'] = pd.Series(lst_flat).astype('float32')\n",
    "\n",
    "    if int(year) >= 2020:\n",
    "        predict_n += 1\n",
    "        predict_lst = np.where(landcover_array != LC_NO_DATA, (predict_lst + lst_array), -9999)\n",
    "        predict_ndvi = np.where(landcover_array != LC_NO_DATA, (predict_ndvi + ndvi_array), -9999)\n",
    "        predict_ndbi = np.where(landcover_array != LC_NO_DATA, (predict_ndbi + ndbi_array), -9999)\n",
    "        predict_albedo = np.where(landcover_array != LC_NO_DATA, (predict_albedo + albedo_array), -9999)\n",
    "\n",
    "\n",
    "    train_df['raster'] = int(file_date_string)\n",
    "\n",
    "    #remove nodata (-9999) from the dataframe\n",
    "    train_df = train_df.loc[\n",
    "        (train_df['landcover'] != LC_NO_DATA)\n",
    "    ]\n",
    "   #urban, uhi = 0\n",
    "    condition = (\n",
    "        ((train_df['landcover'] == URBAN) | \n",
    "         (train_df['landcover'] == INDUSTRIAL) | \n",
    "         (train_df['landcover'] == TRANSPORTATION)) & \n",
    "        (train_df['uhi'] == 0)\n",
    "    )\n",
    "    sampling = train_df.loc[\n",
    "        condition\n",
    "    ].sample(n=sample_n[0])\n",
    "    samples = pd.concat([samples, sampling])\n",
    "\n",
    "    #urban, uhi = 1\n",
    "    condition = (\n",
    "        ((train_df['landcover'] == URBAN) | \n",
    "         (train_df['landcover'] == INDUSTRIAL) | \n",
    "         (train_df['landcover'] == TRANSPORTATION)) & \n",
    "        (train_df['uhi'] == 1)\n",
    "    )\n",
    "    sampling = train_df.loc[\n",
    "        condition\n",
    "    ].sample(n=sample_n[1])\n",
    "    samples = pd.concat([samples, sampling])\n",
    "\n",
    "    #rural/forest/bareland, uhi = 0\n",
    "    condition = (\n",
    "        ((train_df['landcover'] == URBAN_VEGETATION) | \n",
    "         (train_df['landcover'] == RURAL) | \n",
    "         (train_df['landcover'] == FOREST)) & \n",
    "         (train_df['uhi'] == 0)\n",
    "    ) \n",
    "    sampling = train_df.loc[\n",
    "        condition\n",
    "    ].sample(n=sample_n[2])\n",
    "    samples = pd.concat([samples, sampling])\n",
    "\n",
    "    #rural/forest/bareland, uhi = 1\n",
    "    condition = (\n",
    "        ((train_df['landcover'] == URBAN_VEGETATION) | \n",
    "         (train_df['landcover'] == RURAL) | \n",
    "         (train_df['landcover'] == FOREST))& \n",
    "         (train_df['uhi'] == 1)\n",
    "    ) \n",
    "    sampling = train_df.loc[\n",
    "        condition\n",
    "    ].sample(n=sample_n[3])\n",
    "    samples = pd.concat([samples, sampling])\n",
    "    \n",
    "    \n",
    "    all_samples.append(samples)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec0a785f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing LC08_L2SP_194028_20180815_20200831_02_T1\n",
      "data/landcover/DUSAF_2018_MCM_mapped.tif\n",
      "Read land cover\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'uhi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/odc_env/lib/python3.8/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/odc_env/lib/python3.8/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/odc_env/lib/python3.8/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'uhi'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 77\u001b[0m\n\u001b[1;32m     67\u001b[0m train_df \u001b[38;5;241m=\u001b[39m train_df[\n\u001b[1;32m     68\u001b[0m     (train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlandcover\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m LC_NO_DATA) \u001b[38;5;241m&\u001b[39m \n\u001b[1;32m     69\u001b[0m     (train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndvi\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m NO_DATA) \u001b[38;5;241m&\u001b[39m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m     (train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlst\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m NO_DATA)\n\u001b[1;32m     73\u001b[0m ]\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Sample the valid data\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (condition, n_samples) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([\n\u001b[0;32m---> 77\u001b[0m     (((train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlandcover\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m URBAN) \u001b[38;5;241m|\u001b[39m (train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlandcover\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m INDUSTRIAL) \u001b[38;5;241m|\u001b[39m (train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlandcover\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m TRANSPORTATION)) \u001b[38;5;241m&\u001b[39m (\u001b[43mtrain_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muhi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m), sample_n[\u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m     78\u001b[0m     (((train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlandcover\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m URBAN) \u001b[38;5;241m|\u001b[39m (train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlandcover\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m INDUSTRIAL) \u001b[38;5;241m|\u001b[39m (train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlandcover\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m TRANSPORTATION)) \u001b[38;5;241m&\u001b[39m (train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muhi\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m), sample_n[\u001b[38;5;241m1\u001b[39m]),\n\u001b[1;32m     79\u001b[0m     (((train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlandcover\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m URBAN_VEGETATION) \u001b[38;5;241m|\u001b[39m (train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlandcover\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m RURAL) \u001b[38;5;241m|\u001b[39m (train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlandcover\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m FOREST)) \u001b[38;5;241m&\u001b[39m (train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muhi\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m), sample_n[\u001b[38;5;241m2\u001b[39m]),\n\u001b[1;32m     80\u001b[0m     (((train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlandcover\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m URBAN_VEGETATION) \u001b[38;5;241m|\u001b[39m (train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlandcover\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m RURAL) \u001b[38;5;241m|\u001b[39m (train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlandcover\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m FOREST)) \u001b[38;5;241m&\u001b[39m (train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muhi\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m), sample_n[\u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m     81\u001b[0m ]):\n\u001b[1;32m     82\u001b[0m     sampled_data \u001b[38;5;241m=\u001b[39m train_df\u001b[38;5;241m.\u001b[39mloc[condition]\u001b[38;5;241m.\u001b[39msample(n\u001b[38;5;241m=\u001b[39mn_samples, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     83\u001b[0m     samples \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([samples, sampled_data])\n",
      "File \u001b[0;32m~/anaconda3/envs/odc_env/lib/python3.8/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/odc_env/lib/python3.8/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'uhi'"
     ]
    }
   ],
   "source": [
    "samples = pd.DataFrame()\n",
    "predict_n= None\n",
    "sample_n = [\n",
    "    int(total_samples_per_raster / 4),  # urban, uhi 1\n",
    "    int(total_samples_per_raster / 4),  # urban, uhi 0\n",
    "    int(total_samples_per_raster / 4),  # rural/vegetation/bareland, uhi 1\n",
    "    int(total_samples_per_raster / 4),  # rural/vegetation/bareland, uhi 0\n",
    "]\n",
    "\n",
    "for f in file_list:\n",
    "    if check_wrong_files(f):\n",
    "        continue\n",
    "\n",
    "    print(f'Processing {f}')\n",
    "    file_date_string = f.split('_')[3]  # Extract date from filename\n",
    "    year = match_landsat_to_landcover(f)\n",
    "    landcover_path = f'{landcover_base_path}/DUSAF_{year}_MCM_mapped.tif'\n",
    "    print(landcover_path)\n",
    "    \n",
    "    with rasterio.open(landcover_path, driver=\"GTiff\") as landcover_raster:\n",
    "        landcover_array = landcover_raster.read(1)\n",
    "        print('Read land cover')\n",
    "\n",
    "    # Initialize prediction arrays on first iteration\n",
    "    if not isinstance(predict_n,np.ndarray):\n",
    "        predict_n = np.zeros_like(landcover_array, dtype=int)\n",
    "        predict_lst = np.zeros_like(landcover_array, dtype=float)\n",
    "        predict_ndvi = np.zeros_like(landcover_array, dtype=float)\n",
    "        predict_ndbi = np.zeros_like(landcover_array, dtype=float)\n",
    "        predict_albedo = np.zeros_like(landcover_array, dtype=float)\n",
    "\n",
    "    # Load Landsat-derived rasters\n",
    "    #add the uhi column\n",
    "    with rasterio.open(f\"{sat_images_path}/{f}/{f}_uhi.tif\", driver=\"GTiff\") as uhi_raster:\n",
    "        print('read UHI')\n",
    "        uhi_array = uhi_raster.read(1) #UHI band\n",
    "\n",
    "    #add the uhi intensity column\n",
    "    #Uncomment to switch to UHI Intensity instead of UHI binary\n",
    "    \n",
    "    with rasterio.open(f\"{sat_images_path}/{f}/{f}_uhi_int.tif\", driver=\"GTiff\") as uhii_raster:\n",
    "        print('read UHII')\n",
    "        uhii_array = uhii_raster.read(1) #UHI band\n",
    "        \n",
    "    with rasterio.open(f\"{sat_images_path}/{f}/{f}_NDVI.TIF\", driver=\"GTiff\") as ndvi_raster:\n",
    "        ndvi_array = ndvi_raster.read(1)\n",
    "\n",
    "    with rasterio.open(f\"{sat_images_path}/{f}/{f}_NDBI.TIF\", driver=\"GTiff\") as ndbi_raster:\n",
    "        ndbi_array = ndbi_raster.read(1)\n",
    "\n",
    "    with rasterio.open(f\"{sat_images_path}/{f}/{f}_albedo.TIF\", driver=\"GTiff\") as albedo_raster:\n",
    "        albedo_array = albedo_raster.read(1)\n",
    "\n",
    "    with rasterio.open(f\"{sat_images_path}/{f}/{f}_LST.TIF\", driver=\"GTiff\") as lst_raster:\n",
    "        lst_array = lst_raster.read(1)\n",
    "\n",
    "    # Exclude invalid pixels from predictions\n",
    "    valid_pixels = (ndvi_array != NO_DATA) & (ndbi_array != NO_DATA) & (albedo_array != NO_DATA) & (lst_array != NO_DATA)\n",
    "\n",
    "    if int(year) >= 2020:\n",
    "        predict_n += valid_pixels  # Track valid pixel count\n",
    "        predict_lst[valid_pixels] += lst_array[valid_pixels]\n",
    "        predict_ndvi[valid_pixels] += ndvi_array[valid_pixels]\n",
    "        predict_ndbi[valid_pixels] += ndbi_array[valid_pixels]\n",
    "        predict_albedo[valid_pixels] += albedo_array[valid_pixels]\n",
    "\n",
    "    # Remove nodata pixels before sampling\n",
    "    train_df = pd.DataFrame({\n",
    "        'x': np.tile(np.arange(landcover_array.shape[1]), landcover_array.shape[0]),\n",
    "        'y': np.repeat(np.arange(landcover_array.shape[0]), landcover_array.shape[1]),\n",
    "        'landcover': landcover_array.flatten(),\n",
    "        'uhi': uhi_array.flatten(),\n",
    "        'uhii': uhii_array.flatten()\n",
    "        'ndvi': ndvi_array.flatten(),\n",
    "        'ndbi': ndbi_array.flatten(),\n",
    "        'albedo': albedo_array.flatten(),\n",
    "        'lst': lst_array.flatten(),\n",
    "        'raster': file_date_string\n",
    "    })\n",
    "\n",
    "    train_df = train_df[\n",
    "        (train_df['landcover'] != LC_NO_DATA) & \n",
    "        (train_df['ndvi'] != NO_DATA) & \n",
    "        (train_df['ndbi'] != NO_DATA) & \n",
    "        (train_df['albedo'] != NO_DATA) & \n",
    "        (train_df['lst'] != NO_DATA)\n",
    "    ]\n",
    "\n",
    "    # Sample the valid data\n",
    "    for idx, (condition, n_samples) in enumerate([\n",
    "        (((train_df['landcover'] == URBAN) | (train_df['landcover'] == INDUSTRIAL) | (train_df['landcover'] == TRANSPORTATION)) & (train_df['uhi'] == 0), sample_n[0]),\n",
    "        (((train_df['landcover'] == URBAN) | (train_df['landcover'] == INDUSTRIAL) | (train_df['landcover'] == TRANSPORTATION)) & (train_df['uhi'] == 1), sample_n[1]),\n",
    "        (((train_df['landcover'] == URBAN_VEGETATION) | (train_df['landcover'] == RURAL) | (train_df['landcover'] == FOREST)) & (train_df['uhi'] == 0), sample_n[2]),\n",
    "        (((train_df['landcover'] == URBAN_VEGETATION) | (train_df['landcover'] == RURAL) | (train_df['landcover'] == FOREST)) & (train_df['uhi'] == 1), sample_n[3])\n",
    "    ]):\n",
    "        sampled_data = train_df.loc[condition].sample(n=n_samples, random_state=42)\n",
    "        samples = pd.concat([samples, sampled_data])\n",
    "    all_samples.append(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa22f48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving samples in training_samples/MILANO_samples_UHII_50mil.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>landcover</th>\n",
       "      <th>uhi</th>\n",
       "      <th>uhii</th>\n",
       "      <th>ndvi</th>\n",
       "      <th>ndbi</th>\n",
       "      <th>albedo</th>\n",
       "      <th>lst</th>\n",
       "      <th>raster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2524</td>\n",
       "      <td>5424</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.638275</td>\n",
       "      <td>0.603841</td>\n",
       "      <td>-0.102905</td>\n",
       "      <td>0.143713</td>\n",
       "      <td>304.742096</td>\n",
       "      <td>20180815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1075</td>\n",
       "      <td>1404</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.359955</td>\n",
       "      <td>0.346324</td>\n",
       "      <td>-0.082911</td>\n",
       "      <td>0.006920</td>\n",
       "      <td>306.020416</td>\n",
       "      <td>20180815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10338</td>\n",
       "      <td>3614</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.048920</td>\n",
       "      <td>0.669954</td>\n",
       "      <td>-0.226146</td>\n",
       "      <td>0.144723</td>\n",
       "      <td>306.331451</td>\n",
       "      <td>20180815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10598</td>\n",
       "      <td>5304</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.127533</td>\n",
       "      <td>0.539448</td>\n",
       "      <td>-0.183797</td>\n",
       "      <td>0.124097</td>\n",
       "      <td>306.252838</td>\n",
       "      <td>20180815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8954</td>\n",
       "      <td>4967</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.137787</td>\n",
       "      <td>0.836907</td>\n",
       "      <td>-0.349640</td>\n",
       "      <td>0.157759</td>\n",
       "      <td>306.242584</td>\n",
       "      <td>20180815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>6530</td>\n",
       "      <td>6946</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6.176117</td>\n",
       "      <td>0.444094</td>\n",
       "      <td>0.037715</td>\n",
       "      <td>0.157283</td>\n",
       "      <td>311.591797</td>\n",
       "      <td>20200719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>5720</td>\n",
       "      <td>3147</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2.823029</td>\n",
       "      <td>0.898784</td>\n",
       "      <td>-0.469910</td>\n",
       "      <td>0.155451</td>\n",
       "      <td>308.238708</td>\n",
       "      <td>20200719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>4557</td>\n",
       "      <td>5524</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6.996429</td>\n",
       "      <td>0.306539</td>\n",
       "      <td>0.031769</td>\n",
       "      <td>0.203847</td>\n",
       "      <td>312.412109</td>\n",
       "      <td>20200719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>5497</td>\n",
       "      <td>2072</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4.015930</td>\n",
       "      <td>0.809082</td>\n",
       "      <td>-0.388333</td>\n",
       "      <td>0.161463</td>\n",
       "      <td>309.431610</td>\n",
       "      <td>20200719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79999</th>\n",
       "      <td>12618</td>\n",
       "      <td>562</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3.537415</td>\n",
       "      <td>0.892838</td>\n",
       "      <td>-0.433074</td>\n",
       "      <td>0.168806</td>\n",
       "      <td>308.953094</td>\n",
       "      <td>20200719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           x     y  landcover  uhi      uhii      ndvi      ndbi    albedo  \\\n",
       "0       2524  5424          2    0 -1.638275  0.603841 -0.102905  0.143713   \n",
       "1       1075  1404          1    0 -0.359955  0.346324 -0.082911  0.006920   \n",
       "2      10338  3614          1    0 -0.048920  0.669954 -0.226146  0.144723   \n",
       "3      10598  5304          2    0 -0.127533  0.539448 -0.183797  0.124097   \n",
       "4       8954  4967          2    0 -0.137787  0.836907 -0.349640  0.157759   \n",
       "...      ...   ...        ...  ...       ...       ...       ...       ...   \n",
       "79995   6530  6946          5    1  6.176117  0.444094  0.037715  0.157283   \n",
       "79996   5720  3147          6    1  2.823029  0.898784 -0.469910  0.155451   \n",
       "79997   4557  5524          5    1  6.996429  0.306539  0.031769  0.203847   \n",
       "79998   5497  2072          5    1  4.015930  0.809082 -0.388333  0.161463   \n",
       "79999  12618   562          5    1  3.537415  0.892838 -0.433074  0.168806   \n",
       "\n",
       "              lst    raster  \n",
       "0      304.742096  20180815  \n",
       "1      306.020416  20180815  \n",
       "2      306.331451  20180815  \n",
       "3      306.252838  20180815  \n",
       "4      306.242584  20180815  \n",
       "...           ...       ...  \n",
       "79995  311.591797  20200719  \n",
       "79996  308.238708  20200719  \n",
       "79997  312.412109  20200719  \n",
       "79998  309.431610  20200719  \n",
       "79999  308.953094  20200719  \n",
       "\n",
       "[80000 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_base_path = f'training_samples'    \n",
    "# create the \"training_samples\" folder if it does not exist\n",
    "os.makedirs(f\"{samples_base_path}\", exist_ok=True)\n",
    "sufix = '_UHII_50mil'\n",
    "\n",
    "samples_path = f'{samples_base_path}/{city}_samples{sufix}.csv'\n",
    "print(f'Saving samples in {samples_path}')\n",
    "\n",
    "samples_to_save = all_samples[len(all_samples) - 1].copy()\n",
    "samples_to_save = samples_to_save.reset_index(drop=True)\n",
    "samples_to_save.to_csv(samples_path)\n",
    "samples_to_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6712421b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f8ed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute final prediction values, avoiding division by zero\n",
    "valid_mask = predict_n > 0\n",
    "predict_lst[valid_mask] /= predict_n[valid_mask]\n",
    "predict_ndvi[valid_mask] /= predict_n[valid_mask]\n",
    "predict_ndbi[valid_mask] /= predict_n[valid_mask]\n",
    "predict_albedo[valid_mask] /= predict_n[valid_mask]\n",
    "\n",
    "# Convert to DataFrame\n",
    "predict_df = pd.DataFrame({\n",
    "    'x': np.tile(np.arange(landcover_array.shape[1]), landcover_array.shape[0]),\n",
    "    'y': np.repeat(np.arange(landcover_array.shape[0]), landcover_array.shape[1]),\n",
    "    'landcover': landcover_array.flatten().astype('int32'),\n",
    "    'lst': predict_lst.flatten().astype('float32'),\n",
    "    'ndvi': predict_ndvi.flatten().astype('float32'),\n",
    "    'ndbi': predict_ndbi.flatten().astype('float32'),\n",
    "    'albedo': predict_albedo.flatten().astype('float32')\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c082eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the lst and ndvi predict\n",
    "if predict_n == 0: predict_n = 0.0000001\n",
    "predict_lst = np.where(landcover_array != LC_NO_DATA, (predict_lst / predict_n), -9999)\n",
    "predict_ndvi = np.where(landcover_array != LC_NO_DATA, (predict_ndvi / predict_n), -9999)\n",
    "predict_ndbi = np.where(landcover_array != LC_NO_DATA, (predict_ndbi / predict_n), -9999)\n",
    "predict_albedo = np.where(landcover_array != LC_NO_DATA, (predict_albedo / predict_n), -9999)\n",
    "\n",
    "predict_df = pd.DataFrame({'x': x_flat, 'y': y_flat})\n",
    "predict_df['landcover'] = pd.Series(landcover_array.flatten()).astype('int32')\n",
    "predict_df['x'] = predict_df['x'].astype('uint32')\n",
    "predict_df['y'] = predict_df['y'].astype('uint32')\n",
    "predict_df['lst'] = pd.Series(predict_lst.flatten()).astype('float32')\n",
    "predict_df['ndvi'] = pd.Series(predict_ndvi.flatten()).astype('float32')\n",
    "predict_df['ndbi'] = pd.Series(predict_ndbi.flatten()).astype('float32')\n",
    "predict_df['albedo'] = pd.Series(predict_albedo.flatten()).astype('float32')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2463e272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>landcover</th>\n",
       "      <th>lst</th>\n",
       "      <th>ndvi</th>\n",
       "      <th>ndbi</th>\n",
       "      <th>albedo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>3649</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16850</th>\n",
       "      <td>3648</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16851</th>\n",
       "      <td>3649</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16852</th>\n",
       "      <td>3650</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30051</th>\n",
       "      <td>3647</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "      <td>-9999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141141555</th>\n",
       "      <td>12175</td>\n",
       "      <td>10690</td>\n",
       "      <td>5</td>\n",
       "      <td>311.829102</td>\n",
       "      <td>0.529260</td>\n",
       "      <td>-0.115972</td>\n",
       "      <td>0.162138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141141556</th>\n",
       "      <td>12176</td>\n",
       "      <td>10690</td>\n",
       "      <td>5</td>\n",
       "      <td>311.829102</td>\n",
       "      <td>0.529260</td>\n",
       "      <td>-0.115972</td>\n",
       "      <td>0.162138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141141557</th>\n",
       "      <td>12177</td>\n",
       "      <td>10690</td>\n",
       "      <td>5</td>\n",
       "      <td>311.308105</td>\n",
       "      <td>0.568186</td>\n",
       "      <td>-0.153507</td>\n",
       "      <td>0.158356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141141558</th>\n",
       "      <td>12178</td>\n",
       "      <td>10690</td>\n",
       "      <td>5</td>\n",
       "      <td>311.308105</td>\n",
       "      <td>0.568186</td>\n",
       "      <td>-0.153507</td>\n",
       "      <td>0.158356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141141559</th>\n",
       "      <td>12179</td>\n",
       "      <td>10690</td>\n",
       "      <td>5</td>\n",
       "      <td>311.308105</td>\n",
       "      <td>0.568186</td>\n",
       "      <td>-0.153507</td>\n",
       "      <td>0.158356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63010139 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               x      y  landcover          lst         ndvi         ndbi  \\\n",
       "3649        3649      0          6 -9999.000000 -9999.000000 -9999.000000   \n",
       "16850       3648      1          6 -9999.000000 -9999.000000 -9999.000000   \n",
       "16851       3649      1          6 -9999.000000 -9999.000000 -9999.000000   \n",
       "16852       3650      1          6 -9999.000000 -9999.000000 -9999.000000   \n",
       "30051       3647      2          6 -9999.000000 -9999.000000 -9999.000000   \n",
       "...          ...    ...        ...          ...          ...          ...   \n",
       "141141555  12175  10690          5   311.829102     0.529260    -0.115972   \n",
       "141141556  12176  10690          5   311.829102     0.529260    -0.115972   \n",
       "141141557  12177  10690          5   311.308105     0.568186    -0.153507   \n",
       "141141558  12178  10690          5   311.308105     0.568186    -0.153507   \n",
       "141141559  12179  10690          5   311.308105     0.568186    -0.153507   \n",
       "\n",
       "                albedo  \n",
       "3649      -9999.000000  \n",
       "16850     -9999.000000  \n",
       "16851     -9999.000000  \n",
       "16852     -9999.000000  \n",
       "30051     -9999.000000  \n",
       "...                ...  \n",
       "141141555     0.162138  \n",
       "141141556     0.162138  \n",
       "141141557     0.158356  \n",
       "141141558     0.158356  \n",
       "141141559     0.158356  \n",
       "\n",
       "[63010139 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df = predict_df.loc[\n",
    "    (predict_df['landcover'] != LC_NO_DATA) & (predict_df['lst'] != 0) & (predict_df['ndvi'] != 0)\n",
    "]\n",
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1ecc275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving predict in training_samples/MILANO_predict_UHII_50mil.csv\n"
     ]
    }
   ],
   "source": [
    "predict_path = f'{samples_base_path}/{city}_predict{sufix}.csv'\n",
    "print(f'Saving predict in {predict_path}')\n",
    "predict_df = predict_df.reset_index(drop=True)\n",
    "\n",
    "predict_df.to_csv(predict_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (odc_env)",
   "language": "python",
   "name": "odc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
